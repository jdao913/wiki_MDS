Green's function - Wikipedia


From Wikipedia, the free encyclopedia


					Jump to:					navigation, 					search

This article is about the classical approach to Green's functions. For a modern discussion, see fundamental solution.
In mathematics, a Green's function is the impulse response of an inhomogeneous linear differential equation defined on a domain, with specified initial conditions or boundary conditions.
Through the superposition principle for linear operator problems, the convolution of a Green's function with an arbitrary function f (x) on that domain is the solution to the inhomogeneous differential equation for f (x). In other words, given a linear ordinary differential equation (ODE), L(solution) = source, one can first solve L(green) = δs, for each s, and realizing that, since the source is a sum of delta functions, the solution is a sum of Green's functions as well, by linearity of L.
Green's functions are named after the British mathematician George Green, who first developed the concept in the 1830s. In the modern study of linear partial differential equations, Green's functions are studied largely from the point of view of fundamental solutions instead.
Under many-body theory, the term is also used in physics, specifically in quantum field theory, aerodynamics, aeroacoustics, electrodynamics, seismology and statistical field theory, to refer to various types of correlation functions, even those that do not fit the mathematical definition. In quantum field theory, Green's functions take the roles of propagators.



Contents


1 Definition and uses
2 Motivation
3 Green's functions for solving inhomogeneous boundary value problems

3.1 Framework
3.2 Theorem
3.3 Advanced and retarded Green's functions


4 Finding Green's functions

4.1 Units
4.2 Eigenvalue expansions
4.3 Combining Green's functions
4.4 Table of Green's functions


5 Green's functions for the Laplacian
6 Example
7 Further examples
8 See also
9 References
10 External links



Definition and uses[edit]
A Green's function, G(x,s), of a linear differential operator L = L(x) acting on distributions over a subset of the Euclidean space ℝn, at a point s, is any solution of











L
G
(
x
,
s
)
=
δ
(
s
−
x
)
,


{\displaystyle LG(x,s)=\delta (s-x),}








 


 


 




 





(1)







where δ is the Dirac delta function. This property of a Green's function can be exploited to solve differential equations of the form











L
u
(
x
)
=
f
(
x
)
.


{\displaystyle Lu(x)=f(x).}








 


 


 




 





(2)







If the kernel of L is non-trivial, then the Green's function is not unique. However, in practice, some combination of symmetry, boundary conditions and/or other externally imposed criteria will give a unique Green's function. Green's functions may be categorized, by the type of boundary conditions satisfied, by a Green's function number. Also, Green's functions in general are distributions, not necessarily proper functions.
Green's functions are also useful tools in solving wave equations and diffusion equations. In quantum mechanics, the Green's function of the Hamiltonian is a key concept with important links to the concept of density of states.
As a side note, the Green's function as used in physics is usually defined with the opposite sign, instead, that is,





L
G
(
x
,
s
)
=
−
δ
(
x
−
s
)
.


{\displaystyle LG(x,s)=-\delta (x-s).}



This definition does not significantly change any of the properties of the Green's function.
If the operator is translation invariant, that is, when L has constant coefficients with respect to x, then the Green's function can be taken to be a convolution operator, that is,





G
(
x
,
s
)
=
G
(
x
−
s
)
.


{\displaystyle G(x,s)=G(x-s).}



In this case, the Green's function is the same as the impulse response of linear time-invariant system theory.
Motivation[edit]
See also: Spectral theory
Loosely speaking, if such a function G can be found for the operator L, then, if we multiply the equation (1) for the Green's function by f (s), and then integrate with respect to s, we obtain,





∫
L
G
(
x
,
s
)
f
(
s
)

d
s
=
∫
δ
(
x
−
s
)
f
(
s
)

d
s
=
f
(
x
)
.


{\displaystyle \int LG(x,s)f(s)\,ds=\int \delta (x-s)f(s)\,ds=f(x).}



The right-hand side is now given by the equation (2) to be equal to L u(x), thus





L
u
(
x
)
=
∫
L
G
(
x
,
s
)
f
(
s
)

d
s
.


{\displaystyle Lu(x)=\int LG(x,s)f(s)\,ds.}



Because the operator 



L
=
L
(
x
)


{\displaystyle L=L(x)}

 is linear and acts on the variable x alone (not on the variable of integration s), one may take the operator L outside of the integration on the right-hand side, yielding





L
u
(
x
)
=
L

(
∫
G
(
x
,
s
)
f
(
s
)

d
s
)

,


{\displaystyle Lu(x)=L\left(\int G(x,s)f(s)\,ds\right),}



which suggests











u
(
x
)
=
∫
G
(
x
,
s
)
f
(
s
)

d
s
.


{\displaystyle u(x)=\int G(x,s)f(s)\,ds.}








 


 


 




 





(3)







Thus, one may obtain the function u(x) through knowledge of the Green's function in equation (1) and the source term on the right-hand side in equation (2). This process relies upon the linearity of the operator L.
In other words, the solution of equation (2), u(x), can be determined by the integration given in equation (3). Although f (x) is known, this integration cannot be performed unless G is also known. The problem now lies in finding the Green's function G that satisfies equation (1). For this reason, the Green's function is also sometimes called the fundamental solution associated to the operator L.
Not every operator L admits a Green's function. A Green's function can also be thought of as a right inverse of L. Aside from the difficulties of finding a Green's function for a particular operator, the integral in equation (3) may be quite difficult to evaluate. However the method gives a theoretically exact result.
This can be thought of as an expansion of f according to a Dirac delta function basis (projecting f over δ(x−s)); and a superposition of the solution on each projection. Such an integral equation is known as a Fredholm integral equation, the study of which constitutes Fredholm theory.
See also: Volterra integral equation
Green's functions for solving inhomogeneous boundary value problems[edit]
The primary use of Green's functions in mathematics is to solve non-homogeneous boundary value problems. In modern theoretical physics, Green's functions are also usually used as propagators in Feynman diagrams; the term Green's function is often further used for any correlation function.
Framework[edit]
Let L be the Sturm–Liouville operator, a linear differential operator of the form





L
=



d

d
x





[
p
(
x
)



d

d
x




]

+
q
(
x
)


{\displaystyle L={\dfrac {d}{dx}}\left[p(x){\dfrac {d}{dx}}\right]+q(x)}



and let D be the boundary conditions operator





D
u
=


{




α

1



u
′

(
0
)
+

β

1


u
(
0
)





α

2



u
′

(
l
)
+

β

2


u
(
l
)
 
.








{\displaystyle Du={\begin{cases}\alpha _{1}u'(0)+\beta _{1}u(0)\\\alpha _{2}u'(l)+\beta _{2}u(l)~.\end{cases}}}



Let f(x) be a continuous function in [0, l]. Further suppose that the problem









L
u



=
f




D
u



=
0






{\displaystyle {\begin{aligned}Lu&=f\\Du&=0\end{aligned}}}



is regular, i.e., only the trivial solution exists for the homogeneous problem.
Theorem[edit]
There is one and only one solution u(x) that satisfies









L
u



=
f




D
u



=
0
,






{\displaystyle {\begin{aligned}Lu&=f\\Du&=0,\end{aligned}}}



and it is given by





u
(
x
)
=

∫

0


ℓ


f
(
s
)
G
(
x
,
s
)

d
s
 
,


{\displaystyle u(x)=\int _{0}^{\ell }f(s)G(x,s)\,ds~,}



where G(x,s) is a Green's function satisfying the following conditions:





G
(
x
,
s
)


{\displaystyle G(x,s)}

 is continuous in 



x


{\displaystyle x}

 and 



s


{\displaystyle s}

.
For 



x
≠
s


{\displaystyle x\neq s}

, 



L
G
(
x
,
s
)
=
0


{\displaystyle LG(x,s)=0}

.
For 



s
≠
0


{\displaystyle s\neq 0}

, 



D
G
(
x
,
s
)
=
0


{\displaystyle DG(x,s)=0}

.
Derivative "jump": 




G
′

(

s

+
0


,
s
)
−

G
′

(

s

−
0


,
s
)
=
1

/

p
(
s
)


{\displaystyle G'(s_{+0},s)-G'(s_{-0},s)=1/p(s)}

.
Symmetry: 



G
(
x
,
s
)
=
G
(
s
,
x
)


{\displaystyle G(x,s)=G(s,x)}

.

Advanced and retarded Green's functions[edit]
Sometimes the Green's function can be split into a sum of two functions. One with the variable positive (+) and the other with the variable negative (-). These are the advanced and retarded Green's functions, and when the equation under study depends on time, one of the parts is causal and the other anti-causal. In these problems usually the causal part is the important one.
See also: Green's function (many-body theory) and propagator
Finding Green's functions[edit]
Units[edit]
While it doesn't uniquely fix the form the Green's function will take, performing a dimensional analysis to find the units a Green's function must have is an important sanity check on any Green's function found through other means. A quick examination of the defining equation,





L
G
(
x
,
s
)
=
δ
(
x
−
s
)
,


{\displaystyle LG(x,s)=\delta (x-s),}



shows that the units 



G


{\displaystyle G}

 depend not only on the units of 



L


{\displaystyle L}

 but also on the number and units of the space of which the position vectors 



x


{\displaystyle x}

 and 



s


{\displaystyle s}

 are elements. This leads to the relationship:





[
[
G
]
]
=
[
[
L
]

]

−
1


[
[

d

x
]

]

−
1


,


{\displaystyle [[G]]=[[L]]^{-1}[[\mathrm {d} x]]^{-1},}



where 



[
[
G
]
]


{\displaystyle [[G]]}

 is defined as, "the physical units of 



G


{\displaystyle G}

", and 




d

x


{\displaystyle \mathrm {d} x}

 is the volume element of the space (or spacetime).
For example, if 



L
=

∂

t


2




{\displaystyle L=\partial _{t}^{2}}

 and time is the only variable then:





[
[
L
]
]
=
[
[

t
i
m
e

]

]

−
2


,


{\displaystyle [[L]]=[[\mathrm {time} ]]^{-2},}






[
[
d
⁡
x
]
]
=
[
[

t
i
m
e

]
]
,
 

a
n
d



{\displaystyle [[\operatorname {d} x]]=[[\mathrm {time} ]],\ \mathrm {and} }






[
[
G
]
]
=
[
[

t
i
m
e

]
]
.


{\displaystyle [[G]]=[[\mathrm {time} ]].}



If 



L
=
◻
=


1

c

2





∂

t


2


−

∇

2




{\displaystyle L=\square ={\frac {1}{c^{2}}}\partial _{t}^{2}-\nabla ^{2}}

, the d'Alembert operator, and space has 3 dimensions then:





[
[
L
]
]
=
[
[

l
e
n
g
t
h

]

]

−
2


,


{\displaystyle [[L]]=[[\mathrm {length} ]]^{-2},}






[
[
d
⁡
x
]
]
=
[
[

t
i
m
e

]
]
[
[

l
e
n
g
t
h

]

]

3


,
 

a
n
d



{\displaystyle [[\operatorname {d} x]]=[[\mathrm {time} ]][[\mathrm {length} ]]^{3},\ \mathrm {and} }






[
[
G
]
]
=
[
[

t
i
m
e

]

]

−
1


[
[

l
e
n
g
t
h

]

]

−
1


.


{\displaystyle [[G]]=[[\mathrm {time} ]]^{-1}[[\mathrm {length} ]]^{-1}.}



Eigenvalue expansions[edit]
If a differential operator L admits a set of eigenvectors Ψn(x) (i.e., a set of functions Ψn and scalars λn such that LΨn = λn Ψn ) that is complete, then it is possible to construct a Green's function from these eigenvectors and eigenvalues.
"Complete" means that the set of functions { Ψn } satisfies the following completeness relation,





δ
(
x
−

x
′

)
=

∑

n
=
0


∞



Ψ

n


†


(
x
)

Ψ

n


(

x
′

)
.


{\displaystyle \delta (x-x')=\sum _{n=0}^{\infty }\Psi _{n}^{\dagger }(x)\Psi _{n}(x').}



Then the following holds,









G
(
x
,

x
′

)
=

∑

n
=
0


∞







Ψ

n


†


(
x
)

Ψ

n


(

x
′

)


λ

n





,


{\displaystyle G(x,x')=\sum _{n=0}^{\infty }{\dfrac {\Psi _{n}^{\dagger }(x)\Psi _{n}(x')}{\lambda _{n}}},}







where 



†


{\displaystyle \dagger }

 represents complex conjugation.
Applying the operator L to each side of this equation results in the completeness relation, which was assumed.
The general study of the Green's function written in the above form, and its relationship to the function spaces formed by the eigenvectors, is known as Fredholm theory.
There are several other methods for finding Green's functions, including the method of images, separation of variables, and Laplace transforms (Cole 2011).
Combining Green's functions[edit]
If the differential operator 



L


{\displaystyle L}

 can be factored as 



L
=

L

1



L

2




{\displaystyle L=L_{1}L_{2}}

 then the Green's function of 



L


{\displaystyle L}

 can be constructed from the Green's functions for 




L

1




{\displaystyle L_{1}}

 and 




L

2




{\displaystyle L_{2}}

:





G
(
x
,
s
)
=
∫

G

2


(
x
,

s

1


)


G

1


(

s

1


,
s
)
d
⁡

s

1


.


{\displaystyle G(x,s)=\int G_{2}(x,s_{1})\,G_{1}(s_{1},s)\operatorname {d} s_{1}.}



The above identity follows immediately from taking 



G
(
x
,
s
)


{\displaystyle G(x,s)}

 to be the representation of the right operator inverse of 



L


{\displaystyle L}

, analogous to how for the invertable linear operator 



C


{\displaystyle C}

, defined by 



C
=
(
A
B

)

−
1


=

B

−
1



A

−
1




{\displaystyle C=(AB)^{-1}=B^{-1}A^{-1}}

, is represented by its matrix elements 




C

i
,
j




{\displaystyle C_{i,j}}

.
A further identity follows for differential operators that are scalar polynomials of the derivative, 



L
=

P

N


(

∂

x


)


{\displaystyle L=P_{N}(\partial _{x})}

. The fundamental theorem of algebra, combined with the fact that 




∂

x




{\displaystyle \partial _{x}}

 commutes with itself, guarantees that the polynomial can be factored, putting 



L


{\displaystyle L}

 in the form:





L
=

∏

i
=
1


N


(

∂

x


−

z

i


)
,


{\displaystyle L=\prod _{i=1}^{N}(\partial _{x}-z_{i}),}



where 




z

i




{\displaystyle z_{i}}

 are the zeros of 




P

N


(
z
)


{\displaystyle P_{N}(z)}

. Taking the Fourier transform of 



L
G
(
x
,
s
)
=
δ
(
x
−
s
)


{\displaystyle LG(x,s)=\delta (x-s)}

 with respect to both 



x


{\displaystyle x}

 and 



s


{\displaystyle s}

 gives:








G
^



(

k

x


,

k

s


)
=



δ
(

k

x


−

k

s


)



∏

i
=
1


N


(
i

k

x


−

z

i


)



.


{\displaystyle {\hat {G}}(k_{x},k_{s})={\frac {\delta (k_{x}-k_{s})}{\prod _{i=1}^{N}(ik_{x}-z_{i})}}.}



The fraction can then be split into a sum using a Partial fraction decomposition before Fourier transforming back to 



x


{\displaystyle x}

 and 



s


{\displaystyle s}

 space. This process yields identities that relate integrals of Green's functions and sums of the same. For example, if 



L
=
(

∂

x


+
γ
)
(

∂

x


+
α

)

2




{\displaystyle L=(\partial _{x}+\gamma )(\partial _{x}+\alpha )^{2}}

 then one form for its Green's function is:









G
(
x
,
s
)



=


1

(
α
−
γ

)

2





Θ
(
x
−
s
)

e

−
γ
(
x
−
s
)


−


1

(
α
−
γ

)

2





Θ
(
x
−
s
)

e

−
α
(
x
−
s
)


+


1

γ
−
α



Θ
(
x
−
s
)

(
x
−
s
)

e

−
α
(
x
−
s
)








=
∫
Θ
(
x
−

s

1


)
(
x
−

s

1


)

e

−
α
(
x
−

s

1


)


⁡
Θ
(

s

1


−
s
)

e

−
γ
(

s

1


−
s
)


⁡
d
⁡

s

1


.






{\displaystyle {\begin{aligned}G(x,s)&={\frac {1}{(\alpha -\gamma )^{2}}}\Theta (x-s)\operatorname {e} ^{-\gamma (x-s)}-{\frac {1}{(\alpha -\gamma )^{2}}}\Theta (x-s)\operatorname {e} ^{-\alpha (x-s)}+{\frac {1}{\gamma -\alpha }}\Theta (x-s)\,(x-s)\operatorname {e} ^{-\alpha (x-s)}\\&=\int \Theta (x-s_{1})(x-s_{1})\operatorname {e} ^{-\alpha (x-s_{1})}\Theta (s_{1}-s)\operatorname {e} ^{-\gamma (s_{1}-s)}\operatorname {d} s_{1}.\end{aligned}}}



While the example presented is tractable analytically, it illustrates a process that works when the integral is not trivial (for example, when 




∇

2




{\displaystyle \nabla ^{2}}

 is the operator in the polynomial).
Table of Green's functions[edit]
The following table gives an overview of Green's functions of frequently appearing differential operators, where 




r
=



x

2


+

y

2


+

z

2







{\displaystyle \textstyle r={\sqrt {x^{2}+y^{2}+z^{2}}}}

, 




ρ
=



x

2


+

y

2







{\displaystyle \textstyle \rho ={\sqrt {x^{2}+y^{2}}}}

, 




Θ
(
t
)



{\displaystyle \textstyle \Theta (t)}

 is the Heaviside step function, 





J

ν


(
z
)



{\displaystyle \textstyle J_{\nu }(z)}

 is a Bessel function, 





I

ν


(
z
)



{\displaystyle \textstyle I_{\nu }(z)}

 is a modified Bessel function of the first kind, and 





K

ν


(
z
)



{\displaystyle \textstyle K_{\nu }(z)}

 is a modified Bessel function of the second kind.[1] Where time (t) appears in the first column, the advanced (causal) Green's function is listed.


Differential Operator L
Green's Function G
Example of application







∂

t


n
+
1




{\displaystyle \partial _{t}^{n+1}}









t

n



n
!



Θ
(
t
)


{\displaystyle {\frac {t^{n}}{n!}}\Theta (t)}










∂

t


+
γ


{\displaystyle \partial _{t}+\gamma }






Θ
(
t
)


e


−
γ
t




{\displaystyle \Theta (t)\mathrm {e} ^{-\gamma t}}











(

∂

t


+
γ
)


2




{\displaystyle \left(\partial _{t}+\gamma \right)^{2}}






Θ
(
t
)
t


e


−
γ
t




{\displaystyle \Theta (t)t\mathrm {e} ^{-\gamma t}}










∂

t


2


+
2
γ

∂

t


+

ω

0


2




{\displaystyle \partial _{t}^{2}+2\gamma \partial _{t}+\omega _{0}^{2}}






Θ
(
t
)


e


−
γ
t


 



sin
⁡
(
ω
t
)

ω




{\displaystyle \Theta (t)\mathrm {e} ^{-\gamma t}~{\frac {\sin(\omega t)}{\omega }}}

   with   



ω
=



ω

0


2


−

γ

2






{\displaystyle \omega ={\sqrt {\omega _{0}^{2}-\gamma ^{2}}}}


1D damped harmonic oscillator


2D Laplace operator 




Δ

2D


=

∂

x


2


+

∂

y


2




{\displaystyle \Delta _{\text{2D}}=\partial _{x}^{2}+\partial _{y}^{2}}








1

2
π



ln
⁡
ρ


{\displaystyle {\frac {1}{2\pi }}\ln \rho }


2D Poisson equation


3D Laplace operator 




Δ

3D


=

∂

x


2


+

∂

y


2


+

∂

z


2




{\displaystyle \Delta _{\text{3D}}=\partial _{x}^{2}+\partial _{y}^{2}+\partial _{z}^{2}}









−
1


4
π
r





{\displaystyle {\frac {-1}{4\pi r}}}


Poisson equation


Helmholtz operator 




Δ

3D


+

k

2




{\displaystyle \Delta _{\text{3D}}+k^{2}}









−


e


−
i
k
r




4
π
r



=
i



k

32
π
r






{\displaystyle {\frac {-\mathrm {e} ^{-ikr}}{4\pi r}}=i{\sqrt {\frac {k}{32\pi r}}}}






H

1

/

2


(
2
)


(
k
r
)


{\displaystyle H_{1/2}^{(2)}(kr)}





=
i


k

4
π






{\displaystyle =i{\frac {k}{4\pi }}\,}






h

0


(
2
)


(
k
r
)


{\displaystyle h_{0}^{(2)}(kr)}


stationary 3D Schrödinger equation for free particle






Δ
−

k

2




{\displaystyle \Delta -k^{2}}

 in 



n


{\displaystyle n}

 dimensions




−
(
2
π

)

−
n

/

2




(


k
r


)


n

/

2
−
1



K

n

/

2
−
1


(
k
r
)


{\displaystyle -(2\pi )^{-n/2}\left({\frac {k}{r}}\right)^{n/2-1}K_{n/2-1}(kr)}


Yukawa potential, Feynman propagator







∂

t


2


−

c

2



∂

x


2




{\displaystyle \partial _{t}^{2}-c^{2}\partial _{x}^{2}}








1

2
c



Θ
(
t
−

|

x

/

c

|

)


{\displaystyle {\frac {1}{2c}}\Theta (t-|x/c|)}


1D wave equation







∂

t


2


−

c

2



Δ

2D




{\displaystyle \partial _{t}^{2}-c^{2}\Delta _{\text{2D}}}








1

2
π
c



c

2



t

2


−

ρ

2







Θ
(
t
−
ρ

/

c
)


{\displaystyle {\frac {1}{2\pi c{\sqrt {c^{2}t^{2}-\rho ^{2}}}}}\Theta (t-\rho /c)}


2D wave equation


D'Alembert operator 



◻
=


1

c

2





∂

t


2


−

Δ

3D




{\displaystyle \square ={\frac {1}{c^{2}}}\partial _{t}^{2}-\Delta _{\text{3D}}}









δ
(
t
−


r
c


)


4
π
r





{\displaystyle {\frac {\delta (t-{\frac {r}{c}})}{4\pi r}}}


3D wave equation







∂

t


−
k

∂

x


2




{\displaystyle \partial _{t}-k\partial _{x}^{2}}






Θ
(
t
)


(


1

4
π
k
t



)


1

/

2




e


−

x

2



/

4
k
t




{\displaystyle \Theta (t)\left({\frac {1}{4\pi kt}}\right)^{1/2}\mathrm {e} ^{-x^{2}/4kt}}


1D diffusion







∂

t


−
k

Δ

2D




{\displaystyle \partial _{t}-k\Delta _{\text{2D}}}






Θ
(
t
)

(


1

4
π
k
t



)



e


−

ρ

2



/

4
k
t




{\displaystyle \Theta (t)\left({\frac {1}{4\pi kt}}\right)\mathrm {e} ^{-\rho ^{2}/4kt}}


2D diffusion







∂

t


−
k

Δ

3D




{\displaystyle \partial _{t}-k\Delta _{\text{3D}}}






Θ
(
t
)


(


1

4
π
k
t



)


3

/

2




e


−

r

2



/

4
k
t




{\displaystyle \Theta (t)\left({\frac {1}{4\pi kt}}\right)^{3/2}\mathrm {e} ^{-r^{2}/4kt}}


3D diffusion








1

c

2





∂

t


2


−

∂

x


2


+

μ

2




{\displaystyle {\frac {1}{c^{2}}}\partial _{t}^{2}-\partial _{x}^{2}+\mu ^{2}}








1
2



[

(
1
−
sin
⁡

μ
c
t

)

(
δ
(
c
t
−
x
)
+
δ
(
c
t
+
x
)
)
+
μ
Θ
(
c
t
−

|

x

|

)

J

0



(
μ
u
)

]

,

u
=



c

2



t

2


−

x

2






{\displaystyle {\frac {1}{2}}\left[\left(1-\sin {\mu ct}\right)(\delta (ct-x)+\delta (ct+x))+\mu \Theta (ct-|x|)J_{0}\left(\mu u\right)\right],\,u={\sqrt {c^{2}t^{2}-x^{2}}}}


1D Klein–Gordon equation








1

c

2





∂

t


2


−

Δ

2D


+

μ

2




{\displaystyle {\frac {1}{c^{2}}}\partial _{t}^{2}-\Delta _{\text{2D}}+\mu ^{2}}








1

4
π




[
(
1
+
cos
⁡

(
μ
c
t
)

)



δ
(
c
t
−
ρ
)

ρ


+

μ

2


Θ
(
c
t
−
ρ
)
sinc
⁡

(
μ
u
)

]

,

u
=



c

2



t

2


−

ρ

2






{\displaystyle {\frac {1}{4\pi }}\left[(1+\cos {(\mu ct)}){\frac {\delta (ct-\rho )}{\rho }}+\mu ^{2}\Theta (ct-\rho )\operatorname {sinc} {(\mu u)}\right],\,u={\sqrt {c^{2}t^{2}-\rho ^{2}}}}


2D Klein–Gordon equation






◻
+

μ

2




{\displaystyle \square +\mu ^{2}}








1

4
π




[



δ

(
t
−


r
c


)


r


+
μ
c
Θ
(
c
t
−
r
)




J

1



(
μ
u
)


u


]

,

u
=



c

2



t

2


−

r

2






{\displaystyle {\frac {1}{4\pi }}\left[{\frac {\delta \left(t-{\frac {r}{c}}\right)}{r}}+\mu c\Theta (ct-r){\frac {J_{1}\left(\mu u\right)}{u}}\right],\,u={\sqrt {c^{2}t^{2}-r^{2}}}}


3D Klein–Gordon equation







∂

t


2


+
2
γ

∂

t


−

c

2



∂

x


2




{\displaystyle \partial _{t}^{2}+2\gamma \partial _{t}-c^{2}\partial _{x}^{2}}








1
2



e

−
γ
t



[
δ
(
c
t
−
x
)
+
δ
(
c
t
+
x
)
+
Θ
(
c
t
−

|

x

|

)

(


γ
c



I

0



(



γ
u

c


)

+



γ
t

u



I

1



(



γ
u

c


)

)

]

,

u
=



c

2



t

2


−

x

2






{\displaystyle {\frac {1}{2}}e^{-\gamma t}\left[\delta (ct-x)+\delta (ct+x)+\Theta (ct-|x|)\left({\frac {\gamma }{c}}I_{0}\left({\frac {\gamma u}{c}}\right)+{\frac {\gamma t}{u}}I_{1}\left({\frac {\gamma u}{c}}\right)\right)\right],\,u={\sqrt {c^{2}t^{2}-x^{2}}}}


telegrapher's equation







∂

t


2


+
2
γ

∂

t


−

c

2



Δ

2D




{\displaystyle \partial _{t}^{2}+2\gamma \partial _{t}-c^{2}\Delta _{\text{2D}}}









e

−
γ
t



4
π




[
(
1
+

e

−
γ
t


+
3
γ
t
)



δ
(
c
t
−
ρ
)

ρ


+
Θ
(
c
t
−
ρ
)

(



γ
sinh
⁡

(



γ
u

c


)



c
u



+



3
γ
t
cosh
⁡

(



γ
u

c


)



u

2




−



3
c
t
sinh
⁡

(



γ
u

c


)



u

3




)

]

,

u
=



c

2



t

2


−

ρ

2






{\displaystyle {\frac {e^{-\gamma t}}{4\pi }}\left[(1+e^{-\gamma t}+3\gamma t){\frac {\delta (ct-\rho )}{\rho }}+\Theta (ct-\rho )\left({\frac {\gamma \sinh \left({\frac {\gamma u}{c}}\right)}{cu}}+{\frac {3\gamma t\cosh \left({\frac {\gamma u}{c}}\right)}{u^{2}}}-{\frac {3ct\sinh \left({\frac {\gamma u}{c}}\right)}{u^{3}}}\right)\right],\,u={\sqrt {c^{2}t^{2}-\rho ^{2}}}}


2D relativistic heat conduction







∂

t


2


+
2
γ

∂

t


−

c

2



Δ

3D




{\displaystyle \partial _{t}^{2}+2\gamma \partial _{t}-c^{2}\Delta _{\text{3D}}}









e

−
γ
t



20
π




[

(
8
−
3

e

−
γ
t


+
2
γ
t
+
4

γ

2



t

2


)




δ
(
c
t
−
r
)


r

2




+



γ

2


c


Θ
(
c
t
−
r
)

(


1

c
u




I

1



(



γ
u

c


)

+



4
t


u

2





I

2



(



γ
u

c


)

)

]

,

u
=



c

2



t

2


−

r

2






{\displaystyle {\frac {e^{-\gamma t}}{20\pi }}\left[\left(8-3e^{-\gamma t}+2\gamma t+4\gamma ^{2}t^{2}\right){\frac {\delta (ct-r)}{r^{2}}}+{\frac {\gamma ^{2}}{c}}\Theta (ct-r)\left({\frac {1}{cu}}I_{1}\left({\frac {\gamma u}{c}}\right)+{\frac {4t}{u^{2}}}I_{2}\left({\frac {\gamma u}{c}}\right)\right)\right],\,u={\sqrt {c^{2}t^{2}-r^{2}}}}


3D relativistic heat conduction


Green's functions for the Laplacian[edit]
Green's functions for linear differential operators involving the Laplacian may be readily put to use using the second of Green's identities.
To derive Green's theorem, begin with the divergence theorem (otherwise known as Gauss's theorem),






∫

V


∇
⋅



A
→



 
d
V
=

∫

S





A
→



⋅
d



σ
^



 
.


{\displaystyle \int _{V}\nabla \cdot {\vec {A}}\ dV=\int _{S}{\vec {A}}\cdot d{\hat {\sigma }}~.}



Let 






A
→



=
ϕ
∇
ψ
−
ψ
∇
ϕ


{\displaystyle {\vec {A}}=\phi \nabla \psi -\psi \nabla \phi }

 and substitute into Gauss' law.
Compute 



∇
⋅



A
→





{\displaystyle \nabla \cdot {\vec {A}}}

 and apply the product rule for the ∇ operator,









∇
⋅



A
→






=
∇
⋅
(
ϕ
∇
ψ

−

ψ
∇
ϕ
)






=
(
∇
ϕ
)
⋅
(
∇
ψ
)

+

ϕ

∇

2


ψ

−

(
∇
ϕ
)
⋅
(
∇
ψ
)

−

ψ

∇

2


ϕ






=
ϕ

∇

2


ψ

−

ψ

∇

2


ϕ
 
.






{\displaystyle {\begin{aligned}\nabla \cdot {\vec {A}}&=\nabla \cdot (\phi \nabla \psi \;-\;\psi \nabla \phi )\\&=(\nabla \phi )\cdot (\nabla \psi )\;+\;\phi \nabla ^{2}\psi \;-\;(\nabla \phi )\cdot (\nabla \psi )\;-\;\psi \nabla ^{2}\phi \\&=\phi \nabla ^{2}\psi \;-\;\psi \nabla ^{2}\phi ~.\end{aligned}}}



Plugging this into the divergence theorem produces Green's theorem,






∫

V


(
ϕ

∇

2


ψ
−
ψ

∇

2


ϕ
)
d
V
=

∫

S


(
ϕ
∇
ψ
−
ψ
∇
ϕ
)
⋅
d



σ
^



.


{\displaystyle \int _{V}(\phi \nabla ^{2}\psi -\psi \nabla ^{2}\phi )dV=\int _{S}(\phi \nabla \psi -\psi \nabla \phi )\cdot d{\hat {\sigma }}.}



Suppose that the linear differential operator L is the Laplacian, ∇², and that there is a Green's function G for the Laplacian. The defining property of the Green's function still holds,





L
G
(
x
,

x
′

)
=

∇

2


G
(
x
,

x
′

)
=
δ
(
x
−

x
′

)
.


{\displaystyle LG(x,x')=\nabla ^{2}G(x,x')=\delta (x-x').}



Let 



ψ
=
G


{\displaystyle \psi =G}

 in Green's second identity, see Green's identities. Then,






∫

V



[
ϕ
(

x
′

)
δ
(
x
−

x
′

)
−
G
(
x
,

x
′

)



∇
′



2


ϕ
(

x
′

)
]

 

d

3



x
′

=

∫

S



[
ϕ
(

x
′

)

∇
′

G
(
x
,

x
′

)
−
G
(
x
,

x
′

)

∇
′

ϕ
(

x
′

)
]

⋅
d




σ
^



′

.


{\displaystyle \int _{V}\left[\phi (x')\delta (x-x')-G(x,x'){\nabla '}^{2}\phi (x')\right]\ d^{3}x'=\int _{S}\left[\phi (x')\nabla 'G(x,x')-G(x,x')\nabla '\phi (x')\right]\cdot d{\hat {\sigma }}'.}



Using this expression, it is possible to solve Laplace's equation ∇²φ(x) = 0 or Poisson's equation ∇²φ(x) =−ρ(x), subject to either Neumann or Dirichlet boundary conditions. In other words, we can solve for φ(x) everywhere inside a volume where either (1) the value of φ(x) is specified on the bounding surface of the volume (Dirichlet boundary conditions), or (2) the normal derivative of φ(x) is specified on the bounding surface (Neumann boundary conditions).
Suppose the problem is to solve for φ(x) inside the region. Then the integral






∫

V



ϕ
(

x
′

)
δ
(
x
−

x
′

)
 

d

3



x
′




{\displaystyle \int \limits _{V}{\phi (x')\delta (x-x')\ d^{3}x'}}



reduces to simply φ(x) due to the defining property of the Dirac delta function and we have





ϕ
(
x
)
=
−

∫

V


G
(
x
,

x
′

)
ρ
(

x
′

)
 

d

3



x
′

+

∫

S



[
ϕ
(

x
′

)

∇
′

G
(
x
,

x
′

)
−
G
(
x
,

x
′

)

∇
′

ϕ
(

x
′

)
]

⋅
d




σ
^



′

.


{\displaystyle \phi (x)=-\int _{V}G(x,x')\rho (x')\ d^{3}x'+\int _{S}\left[\phi (x')\nabla 'G(x,x')-G(x,x')\nabla '\phi (x')\right]\cdot d{\hat {\sigma }}'.}



This form expresses the well-known property of harmonic functions, that if the value or normal derivative is known on a bounding surface, then the value of the function inside the volume is known everywhere.
In electrostatics, φ(x) is interpreted as the electric potential, ρ(x) as electric charge density, and the normal derivative 



∇
ϕ
(

x
′

)
⋅
d




σ
^



′



{\displaystyle \nabla \phi (x')\cdot d{\hat {\sigma }}'}

 as the normal component of the electric field.
If the problem is to solve a Dirichlet boundary value problem, the Green's function should be chosen such that G(x,x') vanishes when either x or x′ is on the bounding surface. Thus only one of the two terms in the surface integral remains. If the problem is to solve a Neumann boundary value problem, the Green's function is chosen such that its normal derivative vanishes on the bounding surface, as it would seem to be the most logical choice. (See Jackson J.D. classical electrodynamics, page 39). However, application of Gauss's theorem to the differential equation defining the Green's function yields






∫

S



∇
′

G
(
x
,

x
′

)
⋅
d




σ
^



′

=

∫

V



∇

′

2



G
(
x
,

x
′

)

d

3



x
′

=

∫

V


δ
(
x
−

x
′

)

d

3



x
′

=
1
 
,


{\displaystyle \int _{S}\nabla 'G(x,x')\cdot d{\hat {\sigma }}'=\int _{V}\nabla '^{2}G(x,x')d^{3}x'=\int _{V}\delta (x-x')d^{3}x'=1~,}



meaning the normal derivative of G(x,x') cannot vanish on the surface, because it must integrate to 1 on the surface. (Again, see Jackson J.D. classical electrodynamics, page 39 for this and the following argument).
The simplest form the normal derivative can take is that of a constant, namely 1/S, where S is the surface area of the surface. The surface term in the solution becomes






∫

S


ϕ
(

x
′

)

∇
′

G
(
x
,

x
′

)
⋅
d




σ
^



′

=
⟨
ϕ

⟩

S




{\displaystyle \int _{S}\phi (x')\nabla 'G(x,x')\cdot d{\hat {\sigma }}'=\langle \phi \rangle _{S}}



where 



⟨
ϕ

⟩

S




{\displaystyle \langle \phi \rangle _{S}}

 is the average value of the potential on the surface. This number is not known in general, but is often unimportant, as the goal is often to obtain the electric field given by the gradient of the potential, rather than the potential itself.
With no boundary conditions, the Green's function for the Laplacian (Green's function for the three-variable Laplace equation) is





G
(
x
,

x
′

)
=
−



1

4
π

|

x
−

x
′


|





.


{\displaystyle G(x,x')=-{\dfrac {1}{4\pi |x-x'|}}.}



Supposing that the bounding surface goes out to infinity and plugging in this expression for the Green's function finally yields the standard expression for electric potential in terms of electric charge density as









ϕ
(
x
)
=

∫

V






ρ
(

x
′

)


4
π
ε

|

x
−

x
′


|







d

3



x
′

 
.


{\displaystyle \phi (x)=\int _{V}{\dfrac {\rho (x')}{4\pi \varepsilon |x-x'|}}\,d^{3}x'~.}







Further information: Poisson's equation
Example[edit]

Example. Find the Green function for the following problem, whose Green's function number is X11:









L
u



=

u
″

+

k

2


u
=
f
(
x
)




u
(
0
)



=
0
,

u

(



π

2
k




)

=
0.






{\displaystyle {\begin{aligned}Lu&=u''+k^{2}u=f(x)\\u(0)&=0,\quad u\left({\tfrac {\pi }{2k}}\right)=0.\end{aligned}}}




First step: The Green's function for the linear operator at hand is defined as the solution to






g
″

(
x
,
s
)
+

k

2


g
(
x
,
s
)
=
δ
(
x
−
s
)
.


{\displaystyle g''(x,s)+k^{2}g(x,s)=\delta (x-s).}



If 



x
≠
s


{\displaystyle x\neq s}

, then the delta function gives zero, and the general solution is





g
(
x
,
s
)
=

c

1


cos
⁡
k
x
+

c

2


sin
⁡
k
x
.


{\displaystyle g(x,s)=c_{1}\cos kx+c_{2}\sin kx.}



For 



x
<
s


{\displaystyle x<s}

, the boundary condition at 



x
=
0


{\displaystyle x=0}

 implies





g
(
0
,
s
)
=

c

1


⋅
1
+

c

2


⋅
0
=
0
,


c

1


=
0


{\displaystyle g(0,s)=c_{1}\cdot 1+c_{2}\cdot 0=0,\quad c_{1}=0}



if 



x
<
s


{\displaystyle x<s}

 and 



s
≠



π

2
k






{\displaystyle s\neq {\tfrac {\pi }{2k}}}

.
For 



x
>
s


{\displaystyle x>s}

, the boundary condition at 



x
=



π

2
k






{\displaystyle x={\tfrac {\pi }{2k}}}

 implies





g

(



π

2
k




,
s
)

=

c

3


⋅
0
+

c

4


⋅
1
=
0
,


c

4


=
0


{\displaystyle g\left({\tfrac {\pi }{2k}},s\right)=c_{3}\cdot 0+c_{4}\cdot 1=0,\quad c_{4}=0}



The equation of 



g
(
0
,
s
)
=
0


{\displaystyle g(0,s)=0}

 is skipped for similar reasons.
To summarize the results thus far:





g
(
x
,
s
)
=


{




c

2


sin
⁡
k
x
,



for 

x
<
s





c

3


cos
⁡
k
x
,



for 

s
<
x








{\displaystyle g(x,s)={\begin{cases}c_{2}\sin kx,&{\text{for }}x<s\\c_{3}\cos kx,&{\text{for }}s<x\end{cases}}}



Second step: The next task is to determine 




c

2




{\displaystyle c_{2}}

 and 




c

3




{\displaystyle c_{3}}

.
Ensuring continuity in the Green's function at 



x
=
s


{\displaystyle x=s}

 implies






c

2


sin
⁡
k
s
=

c

3


cos
⁡
k
s


{\displaystyle c_{2}\sin ks=c_{3}\cos ks}



One can ensure proper discontinuity in the first derivative by integrating the defining differential equation from 



x
=
s
−
ϵ


{\displaystyle x=s-\epsilon }

 to 



x
=
s
+
ϵ


{\displaystyle x=s+\epsilon }

 and taking the limit as 



ϵ


{\displaystyle \epsilon }

 goes to zero:






c

3


⋅

(
−
k
sin
⁡
k
s
)

−

c

2


⋅

(
k
cos
⁡
k
s
)

=
1


{\displaystyle c_{3}\cdot \left(-k\sin ks\right)-c_{2}\cdot \left(k\cos ks\right)=1}



The two (dis)continuity equations can be solved for 




c

2




{\displaystyle c_{2}}

 and 




c

3




{\displaystyle c_{3}}

 to obtain






c

2


=
−



cos
⁡
k
s

k



;


c

3


=
−



sin
⁡
k
s

k




{\displaystyle c_{2}=-{\frac {\cos ks}{k}}\quad ;\quad c_{3}=-{\frac {\sin ks}{k}}}



So the Green's function for this problem is:





g
(
x
,
s
)
=


{



−



cos
⁡
k
s

k


sin
⁡
k
x
,


x
<
s




−



sin
⁡
k
s

k


cos
⁡
k
x
,


s
<
x








{\displaystyle g(x,s)={\begin{cases}-{\frac {\cos ks}{k}}\sin kx,&x<s\\-{\frac {\sin ks}{k}}\cos kx,&s<x\end{cases}}}



Further examples[edit]

Let n = 1 and let the subset be all of ℝ. Let L be d/dx. Then, the Heaviside step function H(x−x0) is a Green's function of L at x0.
Let n = 2 and let the subset be the quarter-plane {(x, y) : x, y ≥ 0} and L be the Laplacian. Also, assume a Dirichlet boundary condition is imposed at x = 0 and a Neumann boundary condition is imposed at y = 0. Then the X10Y20 Green's function is












G
(
x
,
y
,

x

0


,

y

0


)
=



1

2
π







[
ln
⁡


(
x
−

x

0



)

2


+
(
y
−

y

0



)

2




−
ln
⁡


(
x
+

x

0



)

2


+
(
y
−

y

0



)

2













−
ln
⁡


(
x
−

x

0



)

2


+
(
y
+

y

0



)

2




+
ln
⁡


(
x
+

x

0



)

2


+
(
y
+

y

0



)

2




]





 
.


{\displaystyle {\begin{aligned}G(x,y,x_{0},y_{0})={\dfrac {1}{2\pi }}&\left[\ln {\sqrt {(x-x_{0})^{2}+(y-y_{0})^{2}}}-\ln {\sqrt {(x+x_{0})^{2}+(y-y_{0})^{2}}}\right.\\&\left.-\ln {\sqrt {(x-x_{0})^{2}+(y+y_{0})^{2}}}+\ln {\sqrt {(x+x_{0})^{2}+(y+y_{0})^{2}}}\right]\end{aligned}}~.}






Let 



a
<
x
<
b


{\displaystyle a<x<b}

, and all three are elements of the real numbers. Then, for any function from reals to reals, 



f
(
x
)


{\displaystyle f(x)}

, with an 



n


{\displaystyle n}

th derivative that is integrable over the interval 



[
a
,
b
]


{\displaystyle [a,b]}

:












f
(
x
)



=

∑

m
=
0


n
−
1





(
x
−
a

)

m




m
!





[




d

m


⁡
f


d
⁡

x

m





]


x
=
a


+

∫

a


b



[



(
x
−
s

)

n
−
1




(
n
−
1
)
!



Θ
(
x
−
s
)
]



[




d

n


⁡
f


d
⁡

x

n





]


x
=
s


d
⁡
s




 
.


{\displaystyle {\begin{aligned}f(x)&=\sum _{m=0}^{n-1}{\frac {(x-a)^{m}}{m!}}\left[{\frac {\operatorname {d} ^{m}f}{\operatorname {d} x^{m}}}\right]_{x=a}+\int _{a}^{b}\left[{\frac {(x-s)^{n-1}}{(n-1)!}}\Theta (x-s)\right]\left[{\frac {\operatorname {d} ^{n}f}{\operatorname {d} x^{n}}}\right]_{x=s}\operatorname {d} s\end{aligned}}~.}






The Green's function in the above equation, 



G
(
x
,
s
)
=



(
x
−
s

)

n
−
1




(
n
−
1
)
!



Θ
(
x
−
s
)


{\displaystyle G(x,s)={\frac {(x-s)^{n-1}}{(n-1)!}}\Theta (x-s)}

, is not unique. How is the equation modified if 



g
(
x
−
s
)


{\displaystyle g(x-s)}

 is added to 



G
(
x
,
s
)


{\displaystyle G(x,s)}

, where 



g
(
x
)


{\displaystyle g(x)}

 satisfies 







d

n


⁡
g


d
⁡

x

n





=
0


{\displaystyle {\frac {\operatorname {d} ^{n}g}{\operatorname {d} x^{n}}}=0}

 for all 



x
∈
[
a
,
b
]


{\displaystyle x\in [a,b]}

 (for example, 



g
(
x
)
=
−
x

/

2


{\displaystyle g(x)=-x/2}

 with 



n
=
2


{\displaystyle n=2}

)? Also, compare the above equation to the form of a Taylor series centered at 



x
=
a


{\displaystyle x=a}

.

See also[edit]


Bessel potential
Discrete Green's functions defined on graphs and grids.
Impulse response, the analog of a Green's function in signal processing
Fundamental solution
Green's function in many-body theory
Correlation function (quantum field theory)
Propagator
Green's identities
Parametrix
Volterra integral equation
Resolvent formalism
Keldysh formalism
Spectral theory


References[edit]


S. S. Bayin (2006), Mathematical Methods in Science and Engineering, Wiley, Chapters 18 and 19.
Eyges, Leonard, The Classical Electromagnetic Field, Dover Publications, New York, 1972. ISBN 0-486-63947-9. (Chapter 5 contains a very readable account of using Green's functions to solve boundary value problems in electrostatics.)
A. D. Polyanin and V. F. Zaitsev, Handbook of Exact Solutions for Ordinary Differential Equations (2nd edition), Chapman & Hall/CRC Press, Boca Raton, 2003. ISBN 1-58488-297-2
A. D. Polyanin, Handbook of Linear Partial Differential Equations for Engineers and Scientists, Chapman & Hall/CRC Press, Boca Raton, 2002. ISBN 1-58488-299-9
Mathews, Jon; Walker, Robert L. (1970), Mathematical methods of physics (2nd ed.), New York: W. A. Benjamin, ISBN 0-8053-7002-1
G. B. Folland, Fourier Analysis and Its Applications, Wadsworth and Brooks/Cole Mathematics Series.
K. D. Cole, J. V. Beck, A. Haji-Sheikh, and B. Litkouhi, Methods for obtaining Green's functions, Heat Conduction Using Green's Functions, Taylor and Francis, 2011, pp. 101–148. ISBN 978-1-4398-1354-6
Green G, An Essay on the Application of Mathematical Analysis to the Theories of Electricity and Magnetism (Nottingham, England: T. Wheelhouse, 1828). pages 10-12





^ some examples taken from Schulz, Hermann: Physik mit Bleistift. Frankfurt am Main: Deutsch, 2001. ISBN 3-8171-1661-6 (German)



External links[edit]


Hazewinkel, Michiel, ed. (2001) [1994], "Green function", Encyclopedia of Mathematics, Springer Science+Business Media B.V. / Kluwer Academic Publishers, ISBN 978-1-55608-010-4 
Weisstein, Eric W. "Green's Function". MathWorld. 
Green's function for differential operator at PlanetMath.org.
"Green's function". PlanetMath. 
"GreenFunctionsAndConformalMapping". PlanetMath. 
Introduction to the Keldysh Nonequilibrium Green Function Technique by A. P. Jauho
Green's Function Library
Tutorial on Green's functions
Boundary Element Method (for some idea on how Green's functions may be used with the boundary element method for solving potential problems numerically)
At Citizendium
MIT video lecture on Green's function
Bowley, Roger. "George Green & Green's Functions". Sixty Symbols. Brady Haran for the University of Nottingham. 





Authority control



NDL: 00562581










 
						Retrieved from "https://en.wikipedia.org/w/index.php?title=Green%27s_function&oldid=799510053"					
Categories: Differential equationsGeneralized functionsConcepts in physicsMathematical physics 
