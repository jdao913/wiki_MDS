Linear differential equation - Wikipedia


From Wikipedia, the free encyclopedia 

					Jump to:					navigation, 					search

In mathematics, linear differential equations are differential equations having solutions which can be added together in particular linear combinations to form further solutions. They equate 0 to a polynomial that is linear in the value and various derivatives of a variable; its linearity means that each term in the polynomial has degree either 0 or 1.
Linear differential equations can be ordinary (ODEs) or partial (PDEs).
The solutions to (homogeneous) linear differential equations form a vector space (unlike non-linear differential equations).



Contents


1 Basic features
2 Homogeneous equations with constant coefficients

2.1 Second-order case
2.2 Examples

2.2.1 Simple harmonic oscillator
2.2.2 Damped harmonic oscillator




3 Nonhomogeneous equation with constant coefficients

3.1 Exponential response formula

3.1.1 Example




4 Equation with variable coefficients

4.1 Examples


5 First-order equation with variable coefficients

5.1 Examples


6 Systems of linear differential equations
7 See also
8 Notes
9 External links
10 References



Basic features[edit]
Linear differential equations are of the form





L
y
=
f


{\displaystyle Ly=f}



where the differential operator L is a linear operator, y is the unknown function, and the right hand side f is a given function (called the source term) with the same domain as y. For functions dependent on t (e.g., mimicking "time") we may write the equation more expressly as





L
y
(
t
)
=
f
(
t
)


{\displaystyle Ly(t)=f(t)}



and, even more specific, by bracketing





L
[
y
(
t
)
]
=
f
(
t
)


{\displaystyle L[y(t)]=f(t)}

.

The linearity condition on L rules out operations such as taking the square of the derivative of y; but permits taking higher derivatives of y, by composition of linear operators being themselves linear.
A linear differential operator, involving the n-th derivative, Ln may be considered to be of the form[1]






L

n


[
y
(
t
)
]
≡




d

n


y


d

t

n





+

A

1


(
t
)




d

n
−
1


y


d

t

n
−
1





+
⋯
+

A

n
−
1


(
t
)



d
y


d
t



+

A

n


(
t
)
y


{\displaystyle L_{n}[y(t)]\equiv {\frac {d^{n}y}{dt^{n}}}+A_{1}(t){\frac {d^{n-1}y}{dt^{n-1}}}+\cdots +A_{n-1}(t){\frac {dy}{dt}}+A_{n}(t)y}



It is convenient to rewrite this equation in an operator form






L

n


[
y
]
≡

(


D

n


+

A

1


(
t
)

D

n
−
1


+
⋯
+

A

n
−
1


(
t
)
D
+

A

n


(
t
)
)

[
y
]


{\displaystyle L_{n}[y]\equiv \left(\,D^{n}+A_{1}(t)D^{n-1}+\cdots +A_{n-1}(t)D+A_{n}(t)\right)[y]}



where D is the differential operator d/dt (i.e. Dy = y' = dy/dt , D2y = y" = d2y/dt2,... ), and the An are given functions.
Such an equation is said to have order n, the index of the highest derivative of y that is involved.
A typical simple example is the linear differential equation used to model radioactive decay.[2] Let N(t) denote the number of radioactive atoms remaining in some sample of material [3] at time t. Then for some constant k > 0, the rate at which the radioactive atoms decay can be modelled by








d
N


d
t



=
−
k
N


{\displaystyle {\frac {dN}{dt}}=-kN}



If y is assumed to be a function of only one variable, one speaks about an ordinary differential equation, else the derivatives and their coefficients must be understood as (contracted) vectors, matrices or tensors of higher rank, and we have a (linear) partial differential equation.
The case where f = 0 is called a homogeneous equation and its solutions are called complementary functions. It is particularly important to the solution of the general case, since any complementary function can be added to a solution of the inhomogeneous equation to give another solution (by a method traditionally called particular integral and complementary function). When the Ai are numbers, the equation is said to have constant coefficients.
Homogeneous equations with constant coefficients[edit]
Main article: Characteristic equation (calculus)
The first method of solving linear homogeneous ordinary differential equations with constant coefficients is due to Euler, who realized that solutions have the form ezx, for possibly-complex values of z. The exponential function is one of the few functions to keep its shape after differentiation, allowing the sum of its multiple derivatives to cancel out to zero, as required by the equation. Thus, for constant values A1,..., An, to solve:






y

(
n
)


+

A

1



y

(
n
−
1
)


+
⋯
+

A

n


y
=
0

,


{\displaystyle y^{(n)}+A_{1}y^{(n-1)}+\cdots +A_{n}y=0\,,}



we set y = ezx, leading to






z

n



e

z
x


+

A

1



z

n
−
1



e

z
x


+
⋯
+

A

n



e

z
x


=
0.


{\displaystyle z^{n}e^{zx}+A_{1}z^{n-1}e^{zx}+\cdots +A_{n}e^{zx}=0.}



Division by ezx gives the nth-order polynomial:





F
(
z
)
=

z

n


+

A

1



z

n
−
1


+
⋯
+

A

n


=
0.



{\displaystyle F(z)=z^{n}+A_{1}z^{n-1}+\cdots +A_{n}=0.\,}



This algebraic equation F(z) = 0 is the characteristic equation considered later by Gaspard Monge and Augustin-Louis Cauchy.
Formally, the terms 




y

(
k
)


(
k
=
1
,
2
,
…
,
n
)


{\displaystyle y^{(k)}(k=1,2,\dots ,n)}

 of the original differential equation are replaced by zk. Solving the polynomial gives n values of z, z1, ..., zn. Substitution of any of those values for z into ezx gives a solution ezix. Since homogeneous linear differential equations obey the superposition principle, any linear combination of these functions also satisfies the differential equation.
When these roots are all distinct, we have n distinct solutions to the differential equation. It can be shown that these are linearly independent, by applying the Vandermonde determinant, and together they form a basis of the space of all solutions of the differential equation.


Examples









y
⁗

−
2

y
‴

+
2

y
″

−
2

y
′

+
y
=
0


{\displaystyle y''''-2y'''+2y''-2y'+y=0}



has the characteristic equation






z

4


−
2

z

3


+
2

z

2


−
2
z
+
1
=
0.


{\displaystyle z^{4}-2z^{3}+2z^{2}-2z+1=0.}



This has zeroes, i, −i, and 1 (multiplicity 2). The solution basis is then






e

i
x


,


e

−
i
x


,


e

x


,

x

e

x


.


{\displaystyle e^{ix},\,e^{-ix},\,e^{x},\,xe^{x}.}



This corresponds to the real-valued solution basis





cos
⁡
x
,

sin
⁡
x
,


e

x


,

x

e

x



.


{\displaystyle \cos x,\,\sin x,\,e^{x},\,xe^{x}\,.}







The preceding gave a solution for the case when all zeros are distinct, that is, each has multiplicity 1. For the general case, if z is a (possibly complex) zero (or root) of F(z) having multiplicity m, then, for 



k
∈
{
0
,
1
,
…
,
m
−
1
}



{\displaystyle k\in \{0,1,\dots ,m-1\}\,}

, 



y
=

x

k



e

z
x




{\displaystyle y=x^{k}e^{zx}}

 is a solution of the ordinary differential equation. Applying this to all roots gives a collection of n distinct and linearly independent functions, where n is the degree of F(z). As before, these functions make up a basis of the solution space.
If the coefficients Ai of the differential equation are real, then real-valued solutions are generally preferable. Since non-real roots z then come in conjugate pairs, so do their corresponding basis functions xkezx, and the desired result is obtained by replacing each pair with their real-valued linear combinations Re(y) and Im(y), where y is one of the pair.
A case that involves complex roots can be solved with the aid of Euler's formula.
Second-order case[edit]
In the n=2 case






y
″

+
a

y
′

+
b
y
=
0
,


{\displaystyle y''+ay'+by=0,}



the characteristic equation is of the form






z

2


+
a
z
+
b
=
0.



{\displaystyle z^{2}+az+b=0.\,}



We then can solve for z. There are three particular cases of interest:

Case #1: Two distinct roots, z1 and z2
Case #2: One real repeated root, z
Case #3: Complex roots, α ± βi

In case #1, the general solution is given by





y
=

c

1



e


z

1


x


+

c

2



e


z

2


x


.



{\displaystyle y=c_{1}e^{z_{1}x}+c_{2}e^{z_{2}x}.\,}



In case #2, the general solution is given by





y
=
(

c

1


+

c

2


x
)

e

z
x


.


{\displaystyle y=(c_{1}+c_{2}x)e^{zx}.}



In case #3, the general solution is given, using Euler's equation, by





y
=

c

1



e

α
x


cos
⁡
(
β
x
)
+

c

2



e

α
x


sin
⁡
(
β
x
)
,



{\displaystyle y=c_{1}e^{\alpha x}\cos(\beta x)+c_{2}e^{\alpha x}\sin(\beta x),\,}








α
=



R
e



(
z
)
,



{\displaystyle \alpha ={\mathop {\rm {Re}}}(z),\,}






β
=



I
m



(
z
)
.



{\displaystyle \beta ={\mathop {\rm {Im}}}(z).\,}



In each case, the constants 




c

1


,


c

2




{\displaystyle c_{1},\,c_{2}}

 are functions of the initial conditions 



y
(
0
)
,


y
′

(
0
)
.


{\displaystyle y(0),\,y'(0).}

 They can be found by using the values of the initial conditions in the solution equation for y and in the resulting equation for y' , giving two equations in the two unknown parameters.
Examples[edit]
Given 




y
″

−
4

y
′

+
5
y
=
0


{\displaystyle y''-4y'+5y=0}

. The characteristic equation is 




z

2


−
4
z
+
5
=
0


{\displaystyle z^{2}-4z+5=0}

 which has roots "2±i". Thus the solution basis 



{

y

1


,

y

2


}


{\displaystyle \{y_{1},y_{2}\}}

 is 



{

e

(
2
+
i
)
x


,

e

(
2
−
i
)
x


}


{\displaystyle \{e^{(2+i)x},e^{(2-i)x}\}}

. Now y is a solution if and only if 



y
=

c

1



y

1


+

c

2



y

2




{\displaystyle y=c_{1}y_{1}+c_{2}y_{2}}

 for 




c

1


,

c

2


∈

C



{\displaystyle c_{1},c_{2}\in \mathbf {C} }

.
Because the coefficients are real,

we are likely not interested in the complex solutions
our basis elements are mutual conjugates

The linear combinations






u

1


=

Re

(

y

1


)
=



1
2



(

y

1


+

y

2


)
=

e

2
x


cos
⁡
(
x
)
,


{\displaystyle u_{1}={\mbox{Re}}(y_{1})={\tfrac {1}{2}}(y_{1}+y_{2})=e^{2x}\cos(x),}







u

2


=

Im

(

y

1


)
=



1

2
i




(

y

1


−

y

2


)
=

e

2
x


sin
⁡
(
x
)
,


{\displaystyle u_{2}={\mbox{Im}}(y_{1})={\tfrac {1}{2i}}(y_{1}-y_{2})=e^{2x}\sin(x),}



will give us a real basis in 



{

u

1


,

u

2


}


{\displaystyle \{u_{1},u_{2}\}}

.
Simple harmonic oscillator[edit]
The second order differential equation






D

2


y
=
−

k

2


y
,


{\displaystyle D^{2}y=-k^{2}y,}



which represents a simple harmonic oscillator, can be restated as





(

D

2


+

k

2


)
y
=
0.


{\displaystyle (D^{2}+k^{2})y=0.}



The expression in parenthesis can be factored out, yielding





(
(
D
+
i
k
)
(
D
−
i
k
)
)
y
=
0
,


{\displaystyle ((D+ik)(D-ik))y=0,}



which has a pair of linearly independent solutions:





(
D
−
i
k
)
y
=
0


{\displaystyle (D-ik)y=0}






(
D
+
i
k
)
y
=
0.


{\displaystyle (D+ik)y=0.}



The solutions are, respectively,






y

0


=

A

0



e

i
k
x




{\displaystyle y_{0}=A_{0}e^{ikx}}



and






y

1


=

A

1



e

−
i
k
x


.


{\displaystyle y_{1}=A_{1}e^{-ikx}.}



These solutions provide a basis for the two-dimensional solution space of the second order differential equation: meaning that linear combinations of these solutions will also be solutions. In particular, the following solutions can be constructed






y


0
′



=




C

0



e

i
k
x


+

C

0



e

−
i
k
x



2


=

C

0


cos
⁡
(
k
x
)


{\displaystyle y_{0'}={C_{0}e^{ikx}+C_{0}e^{-ikx} \over 2}=C_{0}\cos(kx)}



and






y


1
′



=




C

1



e

i
k
x


−

C

1



e

−
i
k
x




2
i



=

C

1


sin
⁡
(
k
x
)
.


{\displaystyle y_{1'}={C_{1}e^{ikx}-C_{1}e^{-ikx} \over 2i}=C_{1}\sin(kx).}



These last two trigonometric solutions are linearly independent, so they can serve as another basis for the solution space, yielding the following general solution:






y

H


=

C

0


cos
⁡
(
k
x
)
+

C

1


sin
⁡
(
k
x
)
.


{\displaystyle y_{H}=C_{0}\cos(kx)+C_{1}\sin(kx).}



Damped harmonic oscillator[edit]
Given the equation for the damped harmonic oscillator:






(

D

2


+


b
m


D
+

ω

0


2


)

y
=
0
,


{\displaystyle \left(D^{2}+{\frac {b}{m}}D+\omega _{0}^{2}\right)y=0,}



the expression in parentheses can be factored out: first obtain the characteristic equation by replacing D with z. This equation must be satisfied for all y, thus:






z

2


+


b
m


z
+

ω

0


2


=
0.


{\displaystyle z^{2}+{\frac {b}{m}}z+\omega _{0}^{2}=0.}



Solve using the quadratic formula:





z
=



1
2




(
−


b
m


±





b

2



m

2




−
4

ω

0


2




)

.


{\displaystyle z={\tfrac {1}{2}}\left(-{\frac {b}{m}}\pm {\sqrt {{\frac {b^{2}}{m^{2}}}-4\omega _{0}^{2}}}\right).}



Use these characteristic roots to factor the left side of the original differential equation:






(
D
+


b

2
m



−





b

2



4

m

2





−

ω

0


2




)


(
D
+


b

2
m



+





b

2



4

m

2





−

ω

0


2




)

y
=
0.


{\displaystyle \left(D+{\frac {b}{2m}}-{\sqrt {{\frac {b^{2}}{4m^{2}}}-\omega _{0}^{2}}}\right)\left(D+{\frac {b}{2m}}+{\sqrt {{\frac {b^{2}}{4m^{2}}}-\omega _{0}^{2}}}\right)y=0.}



This implies a pair of solutions, one corresponding to






(
D
+


b

2
m



−





b

2



4

m

2





−

ω

0


2




)

y
=
0


{\displaystyle \left(D+{\frac {b}{2m}}-{\sqrt {{\frac {b^{2}}{4m^{2}}}-\omega _{0}^{2}}}\right)y=0}







(
D
+


b

2
m



+





b

2



4

m

2





−

ω

0


2




)

y
=
0


{\displaystyle \left(D+{\frac {b}{2m}}+{\sqrt {{\frac {b^{2}}{4m^{2}}}-\omega _{0}^{2}}}\right)y=0}



The solutions are, respectively,






y

0


=

A

0



e

−
ω
x
+



ω

2


−

ω

0


2




x


=

A

0



e

−
ω
x



e




ω

2


−

ω

0


2




x




{\displaystyle y_{0}=A_{0}e^{-\omega x+{\sqrt {\omega ^{2}-\omega _{0}^{2}}}x}=A_{0}e^{-\omega x}e^{{\sqrt {\omega ^{2}-\omega _{0}^{2}}}x}}







y

1


=

A

1



e

−
ω
x
−



ω

2


−

ω

0


2




x


=

A

1



e

−
ω
x



e

−



ω

2


−

ω

0


2




x




{\displaystyle y_{1}=A_{1}e^{-\omega x-{\sqrt {\omega ^{2}-\omega _{0}^{2}}}x}=A_{1}e^{-\omega x}e^{-{\sqrt {\omega ^{2}-\omega _{0}^{2}}}x}}



where ω = b/2m. From this linearly independent pair of solutions can be constructed another linearly independent pair which thus serve as a basis for the two-dimensional solution space:






y

H


(

A

0


,

A

1


)
(
x
)
=

(

A

0


sinh
⁡

(



ω

2


−

ω

0


2




x
)

+

A

1


cosh
⁡

(



ω

2


−

ω

0


2




x
)

)


e

−
ω
x


.


{\displaystyle y_{H}(A_{0},A_{1})(x)=\left(A_{0}\sinh \left({\sqrt {\omega ^{2}-\omega _{0}^{2}}}x\right)+A_{1}\cosh \left({\sqrt {\omega ^{2}-\omega _{0}^{2}}}x\right)\right)e^{-\omega x}.}



However, if |ω| < |ω0| then it is preferable to get rid of the consequential imaginaries, expressing the general solution as






y

H


(

A

0


,

A

1


)
(
x
)
=

(

A

0


sin
⁡

(



ω

0


2


−

ω

2




x
)

+

A

1


cos
⁡

(



ω

0


2


−

ω

2




x
)

)


e

−
ω
x


.


{\displaystyle y_{H}(A_{0},A_{1})(x)=\left(A_{0}\sin \left({\sqrt {\omega _{0}^{2}-\omega ^{2}}}x\right)+A_{1}\cos \left({\sqrt {\omega _{0}^{2}-\omega ^{2}}}x\right)\right)e^{-\omega x}.}



This latter solution corresponds to the underdamped case, whereas the former one corresponds to the overdamped case: the solutions for the underdamped case oscillate whereas the solutions for the overdamped case do not.
Nonhomogeneous equation with constant coefficients[edit]
To obtain the solution to the nonhomogeneous equation (sometimes called inhomogeneous equation), find a particular integral yP(x) by the method of undetermined coefficients, method of variation of parameters or the use of the exponential response formula (below); the general solution to the linear differential equation is the sum of the general solution of the related homogeneous equation and the particular integral. Or, when the initial conditions are set, use Laplace transform to obtain the particular solution directly.
Suppose we face









d

n


y
(
x
)


d

x

n





+

A

1






d

n
−
1


y
(
x
)


d

x

n
−
1





+
⋯
+

A

n


y
(
x
)
=
f
(
x
)
.


{\displaystyle {\frac {d^{n}y(x)}{dx^{n}}}+A_{1}{\frac {d^{n-1}y(x)}{dx^{n-1}}}+\cdots +A_{n}y(x)=f(x).}



For later convenience, define the characteristic polynomial





P
(
z
)
=

z

n


+

A

1



z

n
−
1


+
⋯
+

A

n


.


{\displaystyle P(z)=z^{n}+A_{1}z^{n-1}+\cdots +A_{n}.}



We find a solution basis 



{

y

1


(
x
)
,

y

2


(
x
)
,
…
,

y

n


(
x
)
}


{\displaystyle \{y_{1}(x),y_{2}(x),\ldots ,y_{n}(x)\}}

 for the homogeneous (f(x) = 0) case. We now seek a particular integral yp(x) by the variation of parameters method. Let the coefficients of the linear combination be functions of x:






y

p


(
x
)
=

u

1


(
x
)

y

1


(
x
)
+

u

2


(
x
)

y

2


(
x
)
+
⋯
+

u

n


(
x
)

y

n


(
x
)
.


{\displaystyle y_{p}(x)=u_{1}(x)y_{1}(x)+u_{2}(x)y_{2}(x)+\cdots +u_{n}(x)y_{n}(x).}



For ease of notation we will drop the dependency on x (i.e. the various (x)). Using the operator notation D = d/dx, the ODE in question is P(D)y = f; so





f
=
P
(
D
)

y

p


=
P
(
D
)
(

u

1



y

1


)
+
P
(
D
)
(

u

2



y

2


)
+
⋯
+
P
(
D
)
(

u

n



y

n


)
.


{\displaystyle f=P(D)y_{p}=P(D)(u_{1}y_{1})+P(D)(u_{2}y_{2})+\cdots +P(D)(u_{n}y_{n}).}



With the constraints





0
=

u

1

′


y

1


+

u

2

′


y

2


+
⋯
+

u

n

′


y

n




{\displaystyle 0=u'_{1}y_{1}+u'_{2}y_{2}+\cdots +u'_{n}y_{n}}






0
=

u

1

′


y

1

′

+

u

2

′


y

2

′

+
⋯
+

u

n

′


y

n

′



{\displaystyle 0=u'_{1}y'_{1}+u'_{2}y'_{2}+\cdots +u'_{n}y'_{n}}






⋯


{\displaystyle \cdots }






0
=

u

1

′


y

1


(
n
−
2
)


+

u

2

′


y

2


(
n
−
2
)


+
⋯
+

u

n

′


y

n


(
n
−
2
)




{\displaystyle 0=u'_{1}y_{1}^{(n-2)}+u'_{2}y_{2}^{(n-2)}+\cdots +u'_{n}y_{n}^{(n-2)}}



the parameters commute out,





f
=

u

1


P
(
D
)

y

1


+

u

2


P
(
D
)

y

2


+
⋯
+

u

n


P
(
D
)

y

n


+

u

1

′


y

1


(
n
−
1
)


+

u

2

′


y

2


(
n
−
1
)


+
⋯
+

u

n

′


y

n


(
n
−
1
)


.


{\displaystyle f=u_{1}P(D)y_{1}+u_{2}P(D)y_{2}+\cdots +u_{n}P(D)y_{n}+u'_{1}y_{1}^{(n-1)}+u'_{2}y_{2}^{(n-1)}+\cdots +u'_{n}y_{n}^{(n-1)}.}



But P(D)yj = 0, therefore





f
=

u

1

′


y

1


(
n
−
1
)


+

u

2

′


y

2


(
n
−
1
)


+
⋯
+

u

n

′


y

n


(
n
−
1
)


.


{\displaystyle f=u'_{1}y_{1}^{(n-1)}+u'_{2}y_{2}^{(n-1)}+\cdots +u'_{n}y_{n}^{(n-1)}.}



This, with the constraints, gives a linear system in the u′j. This much can always be solved; in fact, combining Cramer's rule with the Wronskian,






u

j

′

=
(
−
1

)

n
+
j





W
(

y

1


,
…
,

y

j
−
1


,

y

j
+
1


…
,

y

n



)



(


0
f


)






W
(

y

1


,

y

2


,
…
,

y

n


)



.


{\displaystyle u'_{j}=(-1)^{n+j}{\frac {W(y_{1},\ldots ,y_{j-1},y_{j+1}\ldots ,y_{n})_{0 \choose f}}{W(y_{1},y_{2},\ldots ,y_{n})}}.}



In the very non-standard notation used above, one should take the i,n-minor of W and multiply it by f. That's why we get a minus-sign. Alternatively, forget about the minus sign and just compute the determinant of the matrix obtained by substituting the j-th W column with (0, 0, ..., f).
The rest is a matter of integrating u′j.
The particular integral is not unique; 




y

p


+

c

1



y

1


+
⋯
+

c

n



y

n




{\displaystyle y_{p}+c_{1}y_{1}+\cdots +c_{n}y_{n}}

 also satisfies the ODE for any set of constants cj.
Exponential response formula[edit]
Main article: Exponential response formula
The particular solution of





P
(
D
)
y
=

∑

i



(


a

i



e


r

i


x



)



{\displaystyle P(D)y=\sum _{i}\left({a_{i}e^{r_{i}x}}\right)}



can be found as






y

p


=

∑

i



(




a

i



P

(

r

i


)





e


r

i


x



)

.


{\displaystyle y_{p}=\sum _{i}\left({{\frac {a_{i}}{P\left(r_{i}\right)}}e^{r_{i}x}}\right).}



Example[edit]
Suppose 




y
″

−
4

y
′

+
5
y
=
sin
⁡
(
k
x
)


{\displaystyle y''-4y'+5y=\sin(kx)}

. We take the solution basis found above 



{

e

(
2
+
i
)
x


=

y

1


(
x
)
,

e

(
2
−
i
)
x


=

y

2


(
x
)
}


{\displaystyle \{e^{(2+i)x}=y_{1}(x),e^{(2-i)x}=y_{2}(x)\}}

.









W



=


|




e

(
2
+
i
)
x





e

(
2
−
i
)
x






(
2
+
i
)

e

(
2
+
i
)
x




(
2
−
i
)

e

(
2
−
i
)
x





|


=

e

4
x




|



1


1




2
+
i


2
−
i



|


=
−
2
i

e

4
x







u

1

′




=


1
W




|



0



e

(
2
−
i
)
x






sin
⁡
(
k
x
)


(
2
−
i
)

e

(
2
−
i
)
x





|


=
−



i
2



sin
⁡
(
k
x
)

e

(
−
2
−
i
)
x







u

2

′




=


1
W




|




e

(
2
+
i
)
x




0




(
2
+
i
)

e

(
2
+
i
)
x




sin
⁡
(
k
x
)



|


=



i
2



sin
⁡
(
k
x
)

e

(
−
2
+
i
)
x


.






{\displaystyle {\begin{aligned}W&={\begin{vmatrix}e^{(2+i)x}&e^{(2-i)x}\\(2+i)e^{(2+i)x}&(2-i)e^{(2-i)x}\end{vmatrix}}=e^{4x}{\begin{vmatrix}1&1\\2+i&2-i\end{vmatrix}}=-2ie^{4x}\\u'_{1}&={\frac {1}{W}}{\begin{vmatrix}0&e^{(2-i)x}\\\sin(kx)&(2-i)e^{(2-i)x}\end{vmatrix}}=-{\tfrac {i}{2}}\sin(kx)e^{(-2-i)x}\\u'_{2}&={\frac {1}{W}}{\begin{vmatrix}e^{(2+i)x}&0\\(2+i)e^{(2+i)x}&\sin(kx)\end{vmatrix}}={\tfrac {i}{2}}\sin(kx)e^{(-2+i)x}.\end{aligned}}}



Using the list of integrals of exponential functions






u

1


=
−



i
2



∫
sin
⁡
(
k
x
)

e

(
−
2
−
i
)
x



d
x
=



i

e

(
−
2
−
i
)
x




2
(
3
+
4
i
+

k

2


)




(
(
2
+
i
)
sin
⁡
(
k
x
)
+
k
cos
⁡
(
k
x
)
)



{\displaystyle u_{1}=-{\tfrac {i}{2}}\int \sin(kx)e^{(-2-i)x}\,dx={\frac {ie^{(-2-i)x}}{2(3+4i+k^{2})}}\left((2+i)\sin(kx)+k\cos(kx)\right)}







u

2


=



i
2



∫
sin
⁡
(
k
x
)

e

(
−
2
+
i
)
x



d
x
=



i

e

(
i
−
2
)
x




2
(
3
−
4
i
+

k

2


)




(
(
i
−
2
)
sin
⁡
(
k
x
)
−
k
cos
⁡
(
k
x
)
)

.


{\displaystyle u_{2}={\tfrac {i}{2}}\int \sin(kx)e^{(-2+i)x}\,dx={\frac {ie^{(i-2)x}}{2(3-4i+k^{2})}}\left((i-2)\sin(kx)-k\cos(kx)\right).}



And so










y

p





=

u

1


(
x
)

y

1


(
x
)
+

u

2


(
x
)

y

2


(
x
)
=


i

2
(
3
+
4
i
+

k

2


)




(
(
2
+
i
)
sin
⁡
(
k
x
)
+
k
cos
⁡
(
k
x
)
)

+


i

2
(
3
−
4
i
+

k

2


)




(
(
i
−
2
)
sin
⁡
(
k
x
)
−
k
cos
⁡
(
k
x
)
)







=



(
5
−

k

2


)
sin
⁡
(
k
x
)
+
4
k
cos
⁡
(
k
x
)


(
3
+

k

2



)

2


+
16



.






{\displaystyle {\begin{aligned}y_{p}&=u_{1}(x)y_{1}(x)+u_{2}(x)y_{2}(x)={\frac {i}{2(3+4i+k^{2})}}\left((2+i)\sin(kx)+k\cos(kx)\right)+{\frac {i}{2(3-4i+k^{2})}}\left((i-2)\sin(kx)-k\cos(kx)\right)\\&={\frac {(5-k^{2})\sin(kx)+4k\cos(kx)}{(3+k^{2})^{2}+16}}.\end{aligned}}}



(Notice that u1 and u2 had factors that canceled y1 and y2; that is typical.)
For interest's sake, this ODE has a physical interpretation as a driven damped harmonic oscillator; yp represents the steady state, and 




c

1



y

1


+

c

2



y

2




{\displaystyle c_{1}y_{1}+c_{2}y_{2}}

 is the transient.
As 



sin
⁡
(
k
x
)
=




e

i
k
x


−

e

−
i
k
x




2
i



,


{\displaystyle \sin(kx)={\frac {e^{ikx}-e^{-ikx}}{2i}},}

 the method of the exponential response formula produces










y

p





=






e

i
k
x



5
−

k

2


−
4
i
k



−



e

−
i
k
x



5
−

k

2


+
4
i
k





2
i









=



(
5
−

k

2


)
sin
⁡
(
k
x
)
+
4
k
cos
⁡
(
k
x
)


(
5
−

k

2



)

2


+
(
4
k

)

2





,






{\displaystyle {\begin{aligned}y_{p}&={\frac {{\frac {e^{ikx}}{5-k^{2}-4ik}}-{\frac {e^{-ikx}}{5-k^{2}+4ik}}}{2i}}\\&={\frac {(5-k^{2})\sin(kx)+4k\cos(kx)}{(5-k^{2})^{2}+(4k)^{2}}},\end{aligned}}}



the same answer as above.
Equation with variable coefficients[edit]
A linear ODE of order n with variable coefficients has the general form






p

n


(
x
)

y

(
n
)


(
x
)
+

p

n
−
1


(
x
)

y

(
n
−
1
)


(
x
)
+
⋯
+

p

0


(
x
)
y
(
x
)
=
r
(
x
)
.


{\displaystyle p_{n}(x)y^{(n)}(x)+p_{n-1}(x)y^{(n-1)}(x)+\cdots +p_{0}(x)y(x)=r(x).}



Examples[edit]
A simple example is the Cauchy–Euler equation often used in engineering






x

n



y

(
n
)


(
x
)
+

a

n
−
1



x

n
−
1



y

(
n
−
1
)


(
x
)
+
⋯
+

a

0


y
(
x
)
=
0.


{\displaystyle x^{n}y^{(n)}(x)+a_{n-1}x^{n-1}y^{(n-1)}(x)+\cdots +a_{0}y(x)=0.}



First-order equation with variable coefficients[edit]


Examples


Solve the equation






y
′

(
x
)
+
3
y
(
x
)
=
2


{\displaystyle y'(x)+3y(x)=2}



with the initial condition





y
(
0
)
=
2.


{\displaystyle y(0)=2.}



Using the general solution method:





y
=

e

−
3
x



(
∫
2

e

3
x



d
x
+
κ
)

.



{\displaystyle y=e^{-3x}\left(\int 2e^{3x}\,dx+\kappa \right).\,}



The indefinite integral is solved to give:





y
=

e

−
3
x



(

(
2

/

3
)


e

3
x


+
κ
)

.



{\displaystyle y=e^{-3x}\left(\left(2/3\right)e^{3x}+\kappa \right).\,}



Then we can reduce to:





y
=
2

/

3
+
κ

e

−
3
x


.



{\displaystyle y=2/3+\kappa e^{-3x}.\,}



where κ = 4/3 from the initial condition.



A linear ODE of order 1 with variable coefficients has the general form





D
y
(
x
)
+
f
(
x
)
y
(
x
)
=
g
(
x
)
.


{\displaystyle Dy(x)+f(x)y(x)=g(x).}



Where D is the differential operator. Equations of this form can be solved by multiplying the integrating factor






e

∫
f
(
x
)

d
x




{\displaystyle e^{\int f(x)\,dx}}



throughout to obtain





D
y
(
x
)

e

∫
f
(
x
)

d
x


+
f
(
x
)
y
(
x
)

e

∫
f
(
x
)

d
x


=
g
(
x
)

e

∫
f
(
x
)

d
x


,


{\displaystyle Dy(x)e^{\int f(x)\,dx}+f(x)y(x)e^{\int f(x)\,dx}=g(x)e^{\int f(x)\,dx},}



which simplifies due to the product rule (applied backwards) to





D

(
y
(
x
)

e

∫
f
(
x
)

d
x


)

=
g
(
x
)

e

∫
f
(
x
)

d
x




{\displaystyle D\left(y(x)e^{\int f(x)\,dx}\right)=g(x)e^{\int f(x)\,dx}}



which, on integrating both sides and solving for y(x) gives:





y
(
x
)
=

e

−
∫
f
(
x
)

d
x



(
∫
g
(
x
)

e

∫
f
(
x
)

d
x



d
x
+
κ
)

.


{\displaystyle y(x)=e^{-\int f(x)\,dx}\left(\int g(x)e^{\int f(x)\,dx}\,dx+\kappa \right).}



In other words: The solution of a first-order linear ODE






y
′

(
x
)
+
f
(
x
)
y
(
x
)
=
g
(
x
)
,


{\displaystyle y'(x)+f(x)y(x)=g(x),}



with coefficients that may or may not vary with x, is:





y
=

e

−
a
(
x
)



(
∫
g
(
x
)

e

a
(
x
)



d
x
+
κ
)



{\displaystyle y=e^{-a(x)}\left(\int g(x)e^{a(x)}\,dx+\kappa \right)}



where κ is the constant of integration, and





a
(
x
)
=
∫

f
(
x
)

d
x

.


{\displaystyle a(x)=\int {f(x)\,dx}.}



A compact form of the general solution based on a Green's function is[4]





y
(
x
)
=

∫

a


x




[
y
(
a
)
δ
(
t
−
a
)
+
g
(
t
)
]

e

−

∫

t


x



f
(
u
)
d
u



d
t


.


{\displaystyle y(x)=\int _{a}^{x}\!{[y(a)\delta (t-a)+g(t)]e^{-\int _{t}^{x}\!f(u)du}\,dt}\,.}



where δ(x) is the generalized Dirac delta function.
Examples[edit]
Consider a first order differential equation with constant coefficients:








d
y


d
x



+
b
y
=
1.


{\displaystyle {\frac {dy}{dx}}+by=1.}



This equation is particularly relevant to first order systems such as RC circuits and mass-damper systems.
In this case, f(x) = b, g(x) = 1.
Hence its solution is





y
(
x
)
=

e

−
b
x



(



e

b
x


b


+
C
)

=


1
b


+
C

e

−
b
x


.


{\displaystyle y(x)=e^{-bx}\left({\frac {e^{bx}}{b}}+C\right)={\frac {1}{b}}+Ce^{-bx}.}



Systems of linear differential equations[edit]
An arbitrary linear ordinary differential equation or even a system of such equations can be converted into a first order system of linear differential equations by adding variables for all but the highest order derivatives. A linear system can be viewed as a single equation with a vector-valued variable. The general treatment is analogous to the treatment above of ordinary first order linear differential equations, but with complications stemming from noncommutativity of matrix multiplication.
To solve






{






y

′

(
x
)


=
A
(
x
)

y

(
x
)
+

b

(
x
)





y

(

x

0


)


=


y


0










{\displaystyle \left\{{\begin{array}{rl}\mathbf {y} '(x)&=A(x)\mathbf {y} (x)+\mathbf {b} (x)\\\mathbf {y} (x_{0})&=\mathbf {y} _{0}\end{array}}\right.}



(here 




y

(
x
)


{\displaystyle \mathbf {y} (x)}

 is a vector or matrix, and 



A
(
x
)


{\displaystyle A(x)}

 is a matrix), let 



U
(
x
)


{\displaystyle U(x)}

 be the solution of 





y

′

(
x
)
=
A
(
x
)

y

(
x
)


{\displaystyle \mathbf {y} '(x)=A(x)\mathbf {y} (x)}

 with 



U
(

x

0


)
=
I


{\displaystyle U(x_{0})=I}

 (the identity matrix). 



U


{\displaystyle U}

 is a fundamental matrix for the equation — the columns of 



U


{\displaystyle U}

 form a complete linearly independent set of solutions for the homogeneous equation. After substituting 




y

(
x
)
=
U
(
x
)

z

(
x
)


{\displaystyle \mathbf {y} (x)=U(x)\mathbf {z} (x)}

, the equation 





y

′

(
x
)
=
A
(
x
)

y

(
x
)
+

b

(
x
)


{\displaystyle \mathbf {y} '(x)=A(x)\mathbf {y} (x)+\mathbf {b} (x)}

 simplifies to 



U
(
x
)


z

′

(
x
)
=

b

(
x
)
.


{\displaystyle U(x)\mathbf {z} '(x)=\mathbf {b} (x).}

 Thus,






y

(
x
)
=
U
(
x
)


y

0



+
U
(
x
)

∫


x

0




x



U

−
1


(
t
)

b

(
t
)

d
t


{\displaystyle \mathbf {y} (x)=U(x)\mathbf {y_{0}} +U(x)\int _{x_{0}}^{x}U^{-1}(t)\mathbf {b} (t)\,dt}



If 



A
(

x

1


)


{\displaystyle A(x_{1})}

 commutes with 



A
(

x

2


)


{\displaystyle A(x_{2})}

 for all 




x

1




{\displaystyle x_{1}}

 and 




x

2




{\displaystyle x_{2}}

, then[citation needed]





U
(
x
)
=

e


∫


x

0




x


A
(
x
)

d
x




{\displaystyle U(x)=e^{\int _{x_{0}}^{x}A(x)\,dx}}



and thus






U

−
1


(
x
)
=

e

−

∫


x

0




x


A
(
x
)

d
x


,


{\displaystyle U^{-1}(x)=e^{-\int _{x_{0}}^{x}A(x)\,dx},}



but in the general case there is no closed form solution, and an approximation method such as Magnus expansion may have to be used. Note that the exponentials are matrix exponentials.
See also[edit]

Matrix differential equation
Partial differential equation
Continuous-repayment mortgage
Fourier transform
Laplace transform
List of differentiation identities, Nth Derivatives Section
Linear difference equation

Notes[edit]



^ Gershenfeld 1999, p.9
^ Robinson 2004, p.5
^ Robinson 2004, p.7
^ J. Math. Chem. 48 (2010), p. 175.



External links[edit]

http://eqworld.ipmnet.ru/en/solutions/ode.htm

References[edit]

Birkhoff, Garrett & Rota, Gian-Carlo (1978), Ordinary Differential Equations, New York: John Wiley and Sons, Inc., ISBN 0-471-07411-X 
Gershenfeld, Neil (1999), The Nature of Mathematical Modeling, Cambridge, UK.: Cambridge University Press, ISBN 978-0-521-57095-4 
Robinson, James C. (2004), An Introduction to Ordinary Differential Equations, Cambridge, UK.: Cambridge University Press, ISBN 0-521-82650-0 







v
t
e


Differential equations



Classification




Operations



Differential operator
Notation for differentiation
Ordinary
Partial
Differential-algebraic
Integro-differential
Fractional
Linear
Non-linear





Attributes of variables



Dependent and independent variables
Homogeneous
Nonhomogeneous
Coupled
Decoupled
Order
Degree
Autonomous
Exact differential equation
Complex differential equation





Relation to processes



Difference (discrete analogue)
stochastic
Delay











Solutions




Solution topics



Picard–Lindelöf theorem (existence and uniqueness)
Wronskian
Phase portrait
Phase space
Lyapunov stability
Asymptotic stability
Exponential stability
Rate of convergence
Series solutions
Integral solutions
Numerical integration
Dirac Delta function





Solution methods



Inspection
Separation of variables
Method of undetermined coefficients
Integrating factor
Integral transforms
Euler method
Finite difference method
Crank–Nicolson method
Runge–Kutta methods
Finite element method
Finite volume method
Galerkin method
Perturbation theory








Applications



Astronomy
Physics
Continuum mechanics
Chaos theory
Chemistry
Dynamical systems
Economics
Biology
Geology
Population dynamics





Mathematicians



Isaac Newton
Leonhard Euler
Émile Picard
Józef Maria Hoene-Wroński
Ernst Lindelöf
Rudolf Lipschitz
Augustin-Louis Cauchy
John Crank
Phyllis Nicolson
Carl David Tolmé Runge
Martin Wilhelm Kutta










 
						Retrieved from "https://en.wikipedia.org/w/index.php?title=Linear_differential_equation&oldid=802142961"					
Categories: Differential equationsHidden categories: All articles with unsourced statementsArticles with unsourced statements from March 2017 
