Speech - Wikipedia


From Wikipedia, the free encyclopedia 

					Jump to:					navigation, 					search

For the process of speaking to a group of people, see Public speaking. For other uses, see Speech (disambiguation).


Play media


Speech production (English) visualized by Real-time MRI




Linguistics


Theoretical





Cognitive
Constraint-based
Generative
Structuralist
Quantitative



Functional theories of grammar



Phonology
Morphology

Morphophonology
Syntax
Lexis
Semantics
Pragmatics
Graphemics
Orthography
Semiotics





Descriptive





Anthropological
Comparative
Historical
Etymology
Graphetics
Phonetics
Sociolinguistics
Cherology





Applied and experimental





Computational
Contrastive

Evolutionary
Forensic
Internet



Language acquisition
Second-language acquisition
Language assessment
Language development
Language education
Linguistic anthropology



Neurolinguistics
Psycholinguistics





Related articles




History of linguistics
Linguistic prescription
List of linguists
Unsolved linguistics problems
Origin of language
Origin of speech




Linguistics portal





v
t
e





Speech is the vocalized form of communication used by humans, which is based upon the syntactic combination of items drawn from the lexicon. Each spoken word is created out of the phonetic combination of a limited set of vowel and consonant speech sound units (phonemes). These vocabularies, the syntax that structures them, and their sets of speech sound units differ, creating many thousands of different, and mutually unintelligible, human languages. The vocal abilities that enable humans to produce speech also enable them to sing.
A gestural form of human communication exists for the deaf in the form of sign language. Speech in some cultures has become the basis of written language, often one that differs in its vocabulary, syntax and phonetics from its associated spoken one, a situation called diglossia. In addition to its use in communication, it is suggested by some psychologists such as Lev Vygotsky that speech is internally used in mental processes to enhance and organize cognition in the form of an interior monologue.
Speech is researched in terms of the speech production and speech perception of the sounds used in vocal language. Other research topics concern speech repetition, the ability to map heard spoken words into the vocalizations needed to recreate them, which plays a key role in vocabulary expansion in children and speech errors. Several academic disciplines study these; including acoustics, psychology, speech pathology, linguistics, cognitive science, communication studies, otolaryngology and computer science. Another area of research is how the human brain in its different areas such as the Broca's area and Wernicke's area underlies speech.
It is controversial how far human speech is unique; in that animals also communicate with vocalizations. While none in the wild have compatibly large vocabularies, research upon the nonverbal abilities of language trained apes such as Washoe and Kanzi raises the possibility that they might have these capabilities. The evolutionary origins of speech are unknown and subject to much debate and speculation.



Contents


1 Production

1.1 Speech Errors


2 Perception
3 Repetition
4 Problems involving speech
5 Brain physiology

5.1 The classical model
5.2 Modern research


6 See also
7 References
8 Further reading
9 External links



Production[edit]
Main articles: Speech production and Linguistics
Speech production is a multi-step process by which thoughts are generated into spoken utterances. Production involves the selection of appropriate words and the appropriate form of those words from the lexicon and morphology, and the organization of those words through the syntax. Then, the phonetic properties of the words are retrieved and the sentence is uttered through the articulations associated with those phonetic properties.[1]
In linguistics (articulatory phonetics), articulation refers to how the tongue, lips, jaw, vocal cords, and other speech organs used to produce sounds are used to make sounds. Speech sounds are categorized by manner of articulation and place of articulation. Place of articulation refers to where the airstream in the mouth is constricted. Manner of articulation refers to the manner in which the speech organs interact, such as how closely the air is restricted, what form of airstream is used (e.g. pulmonic, implosive, ejectives, and clicks), whether or not the vocal cords are vibrating, and whether the nasal cavity is opened to the airstream.[2] The concept is primarily used for the production of consonants, but can be used for vowels in qualities such as voicing and nasalization. For any place of articulation, there may be several manners of articulation, and therefore several homorganic consonants.
Normal human speech is pulmonic, produced with pressure from the lungs, which creates phonation in the glottis in the larynx, which is then modified by the vocal tract and mouth into different vowels and consonants. However humans can pronounce words without the use of the lungs and glottis in alaryngeal speech, of which there are three types: esophageal speech, pharyngeal speech and buccal speech (better known as Donald Duck talk).
Speech Errors[edit]
Main article: Speech error
Speech production is a complex activity, and as a consequence errors are common, especially in children. Speech errors come in many forms and are often used to provide evidence to support hypotheses about the nature of speech.[3] As a result, speech errors are often used in the construction of models for language production and child language acquisition. For example, the fact that children often make the error of over-regularizing the -ed past tense suffix in English (e.g. saying 'singed' instead of 'sang') shows that the regular forms are acquired earlier.[4][5] Speech errors associated with certain kinds of aphasia have been used to map certain components of speech onto the brain and see the relation between different aspects of production: for example, the difficulty of expressive aphasia patients in producing regular past-tense verbs, but not irregulars like 'sing-sang' has been used to demonstrate that regular inflected forms of a word are not individually stored in the lexicon, but produced from affixation of the base form.[6]
Perception[edit]
Main article: Speech perception
Speech perception refers to the processes by which humans can interpret and understand the sounds used in language. The study of speech perception is closely linked to the fields of phonetics and phonology in linguistics and cognitive psychology and perception in psychology. Research in speech perception seeks to understand how listeners recognize speech sounds and use this information to understand spoken language. Research into speech perception also has applications in building computer systems that can recognize speech, as well as improving speech recognition for hearing- and language-impaired listeners.[7]
Speech perception is categorical, in that people put the sounds they hear into categories rather than perceiving them as a spectrum. People are more likely to be able to hear differences in sounds across categorical boundaries than within them. A good example of this is voice onset time (VOT). For example, Hebrew speakers, who distinguish voiced /b/ from voiceless /p/, will more easily detect a change in VOT from -10 ( perceived as /b/ ) to 0 ( perceived as /p/ ) than a change in VOT from +10 to +20, or -10 to -20, despite this being an equally large change on the VOT spectrum.[8]
Repetition[edit]
Main article: Speech repetition
In speech repetition, speech being heard is quickly turned from sensory input into motor instructions needed for its immediate or delayed vocal imitation (in phonological memory). This type of mapping plays a key role in enabling children to expand their spoken vocabulary. Masur (1995) found that how often children repeat novel words versus those they already have in their lexicon is related to the size of their lexicon later on, with young children who repeat more novel words having a larger lexicon later in development. Speech repetition could help facilitate the acquisition of this larger lexicon.[9]
Problems involving speech[edit]
See also: Speech-language pathology
There are several organic and psychological factors that can affect speech. Among these are:

Diseases and disorders of the lungs or the vocal cords, including paralysis, respiratory infections (bronchitis), vocal fold nodules and cancers of the lungs and throat.
Diseases and disorders of the brain, including alogia, aphasias, dysarthria, dystonia and speech processing disorders, where impaired motor planning, nerve transmission, phonological processing or perception of the message (as opposed to the actual sound) leads to poor speech production.
Hearing problems, such as otitis media with effusion, and listening problems, auditory processing disorders, can lead to phonological problems.
Articulatory problems, such as slurred speech, stuttering, lisping, cleft palate, ataxia, or nerve damage leading to problems in articulation. Tourette syndrome and tics can also affect speech. Various congenital and acquired tongue diseases can affect speech as can motor neuron disease.
In addition to dysphasia, anomia and auditory processing disorder can impede the quality of auditory perception, and therefore, expression. Those who are Hard of Hearing or deaf may be considered to fall into this category.

Brain physiology[edit]
The classical model[edit]




Broca's and Wernicke's areas.


The classical or Wernicke-Geschwind model of the language system in the brain focusses on Broca's area in the inferior prefrontal cortex, and Wernicke's area in the posterior superior temporal gyrus on the dominant hemisphere of the brain (typically the left hemisphere for language). In this model, a linguistic auditory signal is first sent from the auditory cortex to Wernicke's area. The lexicon is accessed in Wernicke's area, and these words are sent via the arcuate fasciculus to Broca's area, where morphology, syntax, and instructions for articulation are generated. This is then sent from Broca's area to the motor cortex for articulation.[10]
Paul Broca identified an approximate region of the brain in 1861 which, when damaged in two of his patients, caused severe deficits in speech production, where his patients were unable to speak beyond a few monosyllabic words. This deficit, known as Broca's or expressive aphasia, is characterized by difficulty in speech production where speech is slow and labored, function words are absent, and syntax is severely impaired, as in telegraphic speech. In expressive aphasia, speech comprehension is generally less affected except in the comprehension of grammatically complex sentences.[11] Wernicke's area is named after Carl Wernicke, who in 1874 proposed a connection between damage to the posterior area of the left superior temporal gyrus and aphasia, as he noted that not all aphasic patients had suffered damage to the prefrontal cortex.[12] Damage to Wernicke's area produces Wernicke's or receptive aphasia, which is characterized by relatively normal syntax and prosody but severe impairment in lexical access, resulting in poor comprehension and nonsensical or jargon speech.[11]
Modern research[edit]
Modern models of the neurological systems behind linguistic comprehension and production recognize the importance of Broca's and Wernicke's areas, but are not limited to them nor solely to the left hemisphere. Instead, multiple streams are involved in speech production and comprehension. Damage to the left lateral sulcus has been connected with difficulty in processing and producing morphology and syntax, while lexical access and comprehension of irregular forms (e.g. eat-ate) remain unaffected.[13]
See also[edit]


Language portal
Linguistics portal
Freedom of speech portal
Sociology portal
Anthropology portal



Freedom of speech
FOXP2
Imagined speech
Index of linguistics articles
List of language disorders
Spatial hearing loss
Speechwriter
Talking birds
Vocology

References[edit]



^ Levelt, Willem J. M. (1999). "Models of word production". Trends in Cognitive Sciences. 3 (6): 223–232. 
^ Catford, J.C.; Esling, J.H. (2006). "Articulatory Phonetics". In Brown, Kieth. Encyclopedia of Language & Linguistics (2nd ed.). Amsteram: Elsevier Science. pp. 425–442. 
^ Fromkin, Victoria (1973). "Introduction". Speech Errors as Linguistic Evidence. The Hague: Mouton. pp. 11–46. 
^ Plunkett, Kim; Juola, Patrick (1999). "A connectionist model of english past tense and plural morphology". Cognitive Science. 23 (4): 463–490. 
^ Nicoladis, Elena; Paradis, Johanne. "Acquiring Regular and Irregular Past Tense Morphemes in English and French: Evidence From Bilingual Children". Language Learning. 62 (1): 170–197. 
^ Ullman, Michael T.; et al. (2005). "Neural correlates of lexicon and grammar: Evidence from the production, reading, and judgement of inflection in aphasia". Brain and Language. 93: 185–238. 
^ Kennison, Shelia (2013). Introduction to Language Development. Los Angeles: Sage. 
^ Kishon-Rabin, Liat; Rotshtein, Shira; Taitelbaum, Riki (2002). "Underlying Mechanism for Categorical Perception: Tone-Onset Time and Voice-Onset Time Evidence of Hebrew Voicing". Journal of Basic and Clinical Physiology and Pharmacology. 13 (2): 117–134. 
^ Masur, Elise (1995). "Infants' Early Verbal Imitation and Their Later Lexical Development". Merrill-Palmer Quarterly. 41 (3): 286–306. 
^ Kertesz, A. (2005). "Wernicke--GeschwindModel". In L. Nadel, Encyclopedia of cognitive science. Hoboken, NJ: Wiley.
^ a b Hillis, A. E., & Caramazza, A. (2005). "Aphasia". In L. Nadel, Encyclopedia of cognitive science. Hoboken, NJ: Wiley.
^ Wernicke K. (1995). "The aphasia symptom-complex: A psychological study on an anatomical basis (1875)". In Paul Eling. Reader in the History of Aphasia: From sasi(Franz Gall to). 4. Amsterdam: John Benjamins Pub Co. pp. 69–89. ISBN 90-272-1893-5. 
^ Tyler, Lorraine K.; Marslen-Wilson, William (2009). "Fronto-temporal brain systems supporting spoken language comprehension". In Moore, Brian C. J.; Tyler, Lorraine K.; Marslen-Wilson, William D. The Perception of Speech: from sound to meaning. Oxford: Oxford University Press. pp. 193–217. ISBN 978-0-19-956131-5. 



Further reading[edit]

(in French) Fitzpatrick, Élizabeth M. Apprendre à écouter et à parler. University of Ottawa Press, 2013. Available at Project MUSE.

External links[edit]

Find more aboutSpeechat Wikipedia's sister projects

Definitions from Wiktionary
Media from Commons
News from Wikinews
Quotations from Wikiquote
Texts from Wikisource
Textbooks from Wikibooks
Learning resources from Wikiversity



Speaking captured by real-time MRI, YouTube







v
t
e


Symptoms and signs: Speech and voice / Symptoms involving head and neck (R47–R49, 784)



Aphasias



Acute Aphasias

Expressive aphasia
Receptive aphasia
Conduction aphasia
Anomic aphasia
Global aphasia
Transcortical sensory aphasia
Transcortical motor aphasia
Mixed transcortical aphasia


Progressive Aphasias

Progressive nonfluent aphasia
Semantic dementia
Logopenic progressive aphasia


Speech disturbances

Speech disorder
Developmental verbal dyspraxia/‎Apraxia of speech
Auditory verbal agnosia
Dysarthria
Schizophasia
Aprosodia/Dysprosody
Specific language impairment
Thought disorder
Pressure of speech
Derailment
Clanging
Circumstantiality







Communication disorders



Developmental dyslexia/Alexia
Agnosia

Astereognosis
Prosopagnosia
Visual agnosia


Gerstmann syndrome
Developmental coordination disorder/Apraxia

Ideomotor apraxia


Dyscalculia/Acalculia
Agraphia





Voice disturbances



Dysphonia/Aphonia
Bogart–Bacall syndrome





Nose



Post-nasal drip
Epistaxis





Mouth



Orofacial pain

Toothache
Galvanic pain
Barodontalgia


Fremitus
Tooth mobility
Bruxism
Trismus
Ageusia
Hypogeusia
Dysgeusia
Parageusia
Hypergeusia
Xerostomia
Halitosis
Drooling
Hypersalivation





Neck



Neck mass

Cervical lymphadenopathy







Other



Headache
Auditory processing disorder
Otalgia
Velopharyngeal inadequacy
Velopharyngeal insufficiency
Hypersensitive gag reflex
Jaw claudication
Hypomimia












v
t
e


Communication studies




Topics and
terminology




Biocommunication
Broadcasting
Communication
Computer-mediated communication
Conversation
History of communication
Information
Intercultural / Interpersonal / Intrapersonal communication
Journalism
Mass media
Meaning
Media ecology
Meta-communication
Models of communication
New media
Nonverbal communication
Propaganda
Reading
Speech
Symbol
Telecommunication
Text and conversation theory
Writing








Subfields



Communication design
Communication theory
Communicology
Crisis communication
Cross-cultural communication
Development communication
Discourse analysis
Environmental communication
Health communication
International communication
Mass communication
Media studies
Mediated cross-border communication
Organizational communication
Political communication
Risk communication
Science communication
Technical communication
Visual communication





Related fields



Conversation analysis
Critical theory
Cultural studies
Digital rhetoric
Film criticism
Heritage interpretation
Journalism

photojournalism


Linguistics
Philosophy of language
Political science
Pragmatics
Public relations
Rhetoric
Semiotics
Sociolinguistics
Sociology of culture
Theatre





Scholars



Adorno
Barthes
Bateson
Benjamin
Burke
Castells
Chomsky
Craig
Fisher
Flusser
Gerbner
Goffman
Habermas
Horkheimer
Huxley
Innis
Jakobson
Janis
Johnson
Kincaid
Lippman
Luhmann
Marcuse
McLuhan
Mead
Morgan
Ong
Packard
Peirce
Postman
Quebral
Richards
Rogers
Schramm
Tankard
Tannen
Wertheimer








Category
History
Journals
Organizations
Outline
Scholars
Templates










 
						Retrieved from "https://en.wikipedia.org/w/index.php?title=Speech&oldid=806101596"					
Categories: Oral communicationLanguageSpeechHidden categories: Articles with French-language external linksArticles containing video clips 
